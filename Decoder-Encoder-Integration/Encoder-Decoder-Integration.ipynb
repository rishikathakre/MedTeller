{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"05a4f9bf3b3144618d2eb6d2db11b464":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6bebf809a52492dac40b4dd8078dc5a","IPY_MODEL_b1463f76a44c49ea80eef51e1af618a7","IPY_MODEL_5988a7a1faea4a95963141b5fa510af0"],"layout":"IPY_MODEL_66b269fe193344d18bbbf004d2e74f98"}},"a6bebf809a52492dac40b4dd8078dc5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a61bc0f75e9849d5b9dfe59f440b4150","placeholder":"​","style":"IPY_MODEL_589116bfd026426f8f738c4c913ee284","value":"Map: 100%"}},"b1463f76a44c49ea80eef51e1af618a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4333a29d8ed94c8fb352c1815e4a2a86","max":5223,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe8a307e688e457aad8998be63f595ce","value":5223}},"5988a7a1faea4a95963141b5fa510af0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88addf25875c4920871837871489d4fd","placeholder":"​","style":"IPY_MODEL_c7faa6c5ac5e439bbaf3712313df3a7d","value":" 5223/5223 [00:00&lt;00:00, 7294.44 examples/s]"}},"66b269fe193344d18bbbf004d2e74f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a61bc0f75e9849d5b9dfe59f440b4150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"589116bfd026426f8f738c4c913ee284":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4333a29d8ed94c8fb352c1815e4a2a86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe8a307e688e457aad8998be63f595ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88addf25875c4920871837871489d4fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7faa6c5ac5e439bbaf3712313df3a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4ca2f0c11db4a9086355415b74efeeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_366c147b930e4b10be79c0693da12553","IPY_MODEL_21d7c7be2ca54a7ba2d5fdb7bb1f74da","IPY_MODEL_130a299472c641a1bf3018724aa2a4b4"],"layout":"IPY_MODEL_2089f692f97f4716a292346d963cc80a"}},"366c147b930e4b10be79c0693da12553":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a257742175a4a8f934b78ea21fa796e","placeholder":"​","style":"IPY_MODEL_75c833a24589480aa8ff576b77054e8c","value":"Map: 100%"}},"21d7c7be2ca54a7ba2d5fdb7bb1f74da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d58f45aea30433e8240980aa2e0266e","max":1122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e8ab10427ac4ca3b72558ce825c2dd9","value":1122}},"130a299472c641a1bf3018724aa2a4b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_301700abd7184036be76108141bec125","placeholder":"​","style":"IPY_MODEL_ac327a6bc8294c4d86b01e1845c1d43a","value":" 1122/1122 [00:00&lt;00:00, 13617.28 examples/s]"}},"2089f692f97f4716a292346d963cc80a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a257742175a4a8f934b78ea21fa796e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75c833a24589480aa8ff576b77054e8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d58f45aea30433e8240980aa2e0266e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e8ab10427ac4ca3b72558ce825c2dd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"301700abd7184036be76108141bec125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac327a6bc8294c4d86b01e1845c1d43a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c29c12ccb4f24268828ccbbcb738f0cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf109e5b50374890a9178b75ea380133","IPY_MODEL_cda8bd8077924f1e9ea6f9d97847649b","IPY_MODEL_e70d858da4ef480997491a803b563eec"],"layout":"IPY_MODEL_cde0d8b37afa458092ff438955177a93"}},"bf109e5b50374890a9178b75ea380133":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de0b25669c00450d97eb4d4dfb10c809","placeholder":"​","style":"IPY_MODEL_3e835dce24da41818b3bfed6b9dd98b7","value":"Map: 100%"}},"cda8bd8077924f1e9ea6f9d97847649b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68bc9fe9f3a2439180364934d8dabbd8","max":1121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2b127e60b4e449e84a2e7ca213e55c3","value":1121}},"e70d858da4ef480997491a803b563eec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_588cf043c6e64bef83c312d327cfe0a5","placeholder":"​","style":"IPY_MODEL_dadded5ccab74e3ca2f57206b7c0a38f","value":" 1121/1121 [00:00&lt;00:00, 13898.36 examples/s]"}},"cde0d8b37afa458092ff438955177a93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de0b25669c00450d97eb4d4dfb10c809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e835dce24da41818b3bfed6b9dd98b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68bc9fe9f3a2439180364934d8dabbd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b127e60b4e449e84a2e7ca213e55c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"588cf043c6e64bef83c312d327cfe0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dadded5ccab74e3ca2f57206b7c0a38f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7122524388944cf5865028133cfc34d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c6730424310447f9ec427c548dcb63a","IPY_MODEL_424385b100d94773b379e00adb02f02a","IPY_MODEL_573f467e4c8c41cb91e9c0c6de960978"],"layout":"IPY_MODEL_4e55002e3e174980889522d98d14aa97"}},"8c6730424310447f9ec427c548dcb63a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35bc03fabad6495aa1aebf1fd3b2dc20","placeholder":"​","style":"IPY_MODEL_7f1ee6d8747e428b96a042e4c56ff6c0","value":"Map: 100%"}},"424385b100d94773b379e00adb02f02a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cb7173becf41a2b2b413fd14cdcdf3","max":5223,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1236c23fa0c74d60be803cd951b4b9a0","value":5223}},"573f467e4c8c41cb91e9c0c6de960978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c2d413dd1614071b7f03110febe6a32","placeholder":"​","style":"IPY_MODEL_6bdf2494640f47759695b1be32362632","value":" 5223/5223 [00:00&lt;00:00, 16402.22 examples/s]"}},"4e55002e3e174980889522d98d14aa97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35bc03fabad6495aa1aebf1fd3b2dc20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f1ee6d8747e428b96a042e4c56ff6c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7cb7173becf41a2b2b413fd14cdcdf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1236c23fa0c74d60be803cd951b4b9a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c2d413dd1614071b7f03110febe6a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bdf2494640f47759695b1be32362632":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ed0a336c144cb085b71a9269524a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db34a1eff03742fc9703f1cd270f47bb","IPY_MODEL_d436f4ffdd9042fb864d3ffb4e7de7d4","IPY_MODEL_45360639d26946fd8e4bdde5753fdd46"],"layout":"IPY_MODEL_19f305cae7a94e2fabb269261d9a5dbc"}},"db34a1eff03742fc9703f1cd270f47bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6850c4039b5d466182ccae45f5520027","placeholder":"​","style":"IPY_MODEL_786c936d8eb249a1b0d72463c7575da0","value":"Map: 100%"}},"d436f4ffdd9042fb864d3ffb4e7de7d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdf8387b82e247f7a810619e82b75843","max":1122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f5de1398a924ad99c3a41580d67e2ea","value":1122}},"45360639d26946fd8e4bdde5753fdd46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a933492a89a4e86ae7ba0325e45bbfe","placeholder":"​","style":"IPY_MODEL_29f2ae9b070842bf8cf9a57e403fec33","value":" 1122/1122 [00:00&lt;00:00, 14684.99 examples/s]"}},"19f305cae7a94e2fabb269261d9a5dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6850c4039b5d466182ccae45f5520027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"786c936d8eb249a1b0d72463c7575da0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdf8387b82e247f7a810619e82b75843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f5de1398a924ad99c3a41580d67e2ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a933492a89a4e86ae7ba0325e45bbfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29f2ae9b070842bf8cf9a57e403fec33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee8d4ae62e574ed1930fba11f3a97aec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f92b660acb6c4eca9cfa853f875459b0","IPY_MODEL_0b4d7675ec3c4f3690525ae8db50a721","IPY_MODEL_4ea7af8b13ce4f2ea23cbb4c43a07097"],"layout":"IPY_MODEL_5bccfbff6d0f420d9f1c27fc6c3b21ee"}},"f92b660acb6c4eca9cfa853f875459b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06ecb2803804d0cb3c875254b919a31","placeholder":"​","style":"IPY_MODEL_bf3a2d5e1d164ff29744a0933f85aa5b","value":"Map: 100%"}},"0b4d7675ec3c4f3690525ae8db50a721":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_661224461e664c1ba62df50239ec7440","max":1121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc143a50be174e27973891871f5042bb","value":1121}},"4ea7af8b13ce4f2ea23cbb4c43a07097":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58845df187d34ed3bd2c4f991dbccc3d","placeholder":"​","style":"IPY_MODEL_6f3e62aa521440389fe49f6dafd7ac77","value":" 1121/1121 [00:00&lt;00:00, 14326.81 examples/s]"}},"5bccfbff6d0f420d9f1c27fc6c3b21ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06ecb2803804d0cb3c875254b919a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf3a2d5e1d164ff29744a0933f85aa5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"661224461e664c1ba62df50239ec7440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc143a50be174e27973891871f5042bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58845df187d34ed3bd2c4f991dbccc3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f3e62aa521440389fe49f6dafd7ac77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9dd70b73e3a477ca7610fe925ca5d42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3bed9230ca24b1d913abf032b5ffd1a","IPY_MODEL_f296887a595a44f88e45b4208673bb8b","IPY_MODEL_435234221bee4c47adce3d5ed49c9c6b"],"layout":"IPY_MODEL_6c4628dce9814c00a79e2a1cca00ccf3"}},"c3bed9230ca24b1d913abf032b5ffd1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f5b3f719bca416c9f620ed04f9dba20","placeholder":"​","style":"IPY_MODEL_3aed5bde04204bf6b42eb9f8cea0ccb2","value":"Map: 100%"}},"f296887a595a44f88e45b4208673bb8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85cf42d6d14e489fa8985b0df3d87d53","max":5223,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1886e78e2ae14a108bf2692ba810e7aa","value":5223}},"435234221bee4c47adce3d5ed49c9c6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4cfd7f8d39b45a68c54eec2ba283607","placeholder":"​","style":"IPY_MODEL_4d74c2f17ec341e8b3f32c11aea560e5","value":" 5223/5223 [00:00&lt;00:00, 16378.88 examples/s]"}},"6c4628dce9814c00a79e2a1cca00ccf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f5b3f719bca416c9f620ed04f9dba20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aed5bde04204bf6b42eb9f8cea0ccb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85cf42d6d14e489fa8985b0df3d87d53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1886e78e2ae14a108bf2692ba810e7aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4cfd7f8d39b45a68c54eec2ba283607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d74c2f17ec341e8b3f32c11aea560e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afc1ed05e3e04e568349db2c7413a2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_020e7877262741518c2cdecdf32a6dfe","IPY_MODEL_c33c38997fe44492aaa1c32028198c4c","IPY_MODEL_77069d34dd4645699066123136a55e65"],"layout":"IPY_MODEL_c34bf70d0883487089c8f33a4ed31614"}},"020e7877262741518c2cdecdf32a6dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_671ca49dfe964bbabb04d40417e4653e","placeholder":"​","style":"IPY_MODEL_b1e28242b95c46418c46fc179e44ff72","value":"Map: 100%"}},"c33c38997fe44492aaa1c32028198c4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a283e911c4441e592f12591124ac2c1","max":1122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6835f5daa92a40b3ad8f7c799aea5a01","value":1122}},"77069d34dd4645699066123136a55e65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14e159a47df74a3ebafb4404f2cf522d","placeholder":"​","style":"IPY_MODEL_c240b1fb51fa481093874680361a2d07","value":" 1122/1122 [00:00&lt;00:00, 13937.62 examples/s]"}},"c34bf70d0883487089c8f33a4ed31614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"671ca49dfe964bbabb04d40417e4653e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1e28242b95c46418c46fc179e44ff72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a283e911c4441e592f12591124ac2c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6835f5daa92a40b3ad8f7c799aea5a01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14e159a47df74a3ebafb4404f2cf522d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c240b1fb51fa481093874680361a2d07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"749367b963c1412f95e83c7c3dcf8ab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c84ec90234184a74b5ef4d9ea9a69c17","IPY_MODEL_1cbd79030b32410988c03c44caf2295f","IPY_MODEL_a59611236cba49c383d78f731347bdb0"],"layout":"IPY_MODEL_61d7a2865e744e3da8c0c99b188cb709"}},"c84ec90234184a74b5ef4d9ea9a69c17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c1f7a56737f489ba32d6a3b4fc0c475","placeholder":"​","style":"IPY_MODEL_f183c447d17e49f8befb9c8bb5b57e01","value":"Map: 100%"}},"1cbd79030b32410988c03c44caf2295f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8a6ffd2064c4d528aa11d436b17ef52","max":1121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25442bdcc11e49e18b2378eedc0bd29a","value":1121}},"a59611236cba49c383d78f731347bdb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3493c4c20e78417a8db91afa05049330","placeholder":"​","style":"IPY_MODEL_737ad2cce8bc4243a142699aaeeeb564","value":" 1121/1121 [00:00&lt;00:00, 14285.02 examples/s]"}},"61d7a2865e744e3da8c0c99b188cb709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c1f7a56737f489ba32d6a3b4fc0c475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f183c447d17e49f8befb9c8bb5b57e01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8a6ffd2064c4d528aa11d436b17ef52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25442bdcc11e49e18b2378eedc0bd29a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3493c4c20e78417a8db91afa05049330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737ad2cce8bc4243a142699aaeeeb564":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## On Zaratan, you may wanna do:\n","\n","USE_SAMPLE_TEXT = False     # full text dataset\n","MAX_TRAIN_MM = None         # use all multimodal train samples\n","MAX_VAL_MM   = None         # use all multimodal val samples\n"],"metadata":{"id":"TKhHUBOPwNyT"}},{"cell_type":"code","source":["!pip install -q transformers datasets accelerate\n"],"metadata":{"id":"zwwcmhDVbqUD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3Kg4T2NM5YY","executionInfo":{"status":"ok","timestamp":1764726657543,"user_tz":300,"elapsed":12188,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"a0e01a6e-11ea-4f98-ee16-2acc6fe38665"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Device: cuda\n","\n","Searching under: /content/drive\n","\n","Found processed_data.csv matches:\n","   /content/drive/MyDrive/processed data/data/data/processed_data.csv\n","\n","Inferred BASE_DIR: /content/drive/MyDrive/processed data/data/data\n","Contents of BASE_DIR: ['sample_data.csv', 'images', 'processed_data.csv', 'sample_decoder_tokenizer', 'sample_decoder_pretrained', 'sample_multimodal_decoder']\n","\n","Found multimodal_dataset_full.pt matches:\n","   /content/drive/MyDrive/processed data/encoder for full data/multimodal_dataset_full.pt\n","\n","Using EMBEDDINGS_DIR: /content/drive/MyDrive/processed data/encoder for full data\n","Using MM_FULL_PATH: /content/drive/MyDrive/processed data/encoder for full data/multimodal_dataset_full.pt\n"]}],"source":["# ==== Global config, mount Drive, locate processed data + multimodal embeddings ====\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","import os\n","import glob\n","import math\n","import torch\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from datasets import Dataset, DatasetDict\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    DataCollatorForLanguageModeling,\n","    TrainingArguments,\n","    Trainer,\n",")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", device)\n","\n","# ---------------- High-level toggles ----------------\n","# Use small sample_data vs full processed_data text CSV\n","USE_SAMPLE_TEXT = False     # True for Colab debugging, False for full decoder training\n","\n","\n","# Use subset of multimodal samples (train/val) for Colab\n","MAX_TRAIN_MM = None          # set to None on Zaratan if you want to use ALL\n","MAX_VAL_MM   = None          # set to None on Zaratan for ALL val\n","\n","# Text-only decoder hyperparams\n","TEXT_NUM_EPOCHS  = 5\n","TEXT_LR          = 5e-5\n","TEXT_TRAIN_BS    = 8\n","TEXT_EVAL_BS     = 8\n","TEXT_GRAD_ACCUM  = 4\n","TEXT_MAX_LENGTH  = 256\n","\n","# Multimodal decoder hyperparams\n","MM_NUM_EPOCHS    = 10\n","MM_LR            = 2e-5\n","MM_TRAIN_BS      = 4\n","MM_EVAL_BS       = 4\n","MM_GRAD_ACCUM    = 4\n","MM_MAX_LENGTH    = 256\n","COND_DIM         = 1536    # 768 (ViT pooled) + 768 (ClinicalBERT)\n","\n","# ---------------- Locate processed_data.csv (text) ----------------\n","ROOT = \"/content/drive\"\n","print(\"\\nSearching under:\", ROOT)\n","\n","proc_matches = glob.glob(os.path.join(ROOT, \"**\", \"processed_data.csv\"), recursive=True)\n","print(\"\\nFound processed_data.csv matches:\")\n","for m in proc_matches:\n","    print(\"  \", m)\n","\n","if not proc_matches:\n","    raise FileNotFoundError(\n","        \"Could not find processed_data.csv anywhere under /content/drive. \"\n","        \"Make sure the shared 'processed data' folder is visible in Drive.\"\n","    )\n","\n","BASE_DIR = os.path.dirname(proc_matches[0])\n","\n","print(\"\\nInferred BASE_DIR:\", BASE_DIR)\n","print(\"Contents of BASE_DIR:\", os.listdir(BASE_DIR))\n","\n","# ---------------- Locate multimodal_dataset_full.pt ----------------\n","mm_full_matches = glob.glob(os.path.join(ROOT, \"**\", \"multimodal_dataset_full.pt\"), recursive=True)\n","print(\"\\nFound multimodal_dataset_full.pt matches:\")\n","for m in mm_full_matches:\n","    print(\"  \", m)\n","\n","if not mm_full_matches:\n","    raise FileNotFoundError(\n","        \"Could not find multimodal_dataset_full.pt under /content/drive. \"\n","        \"Make sure the 'Dataset Embeddings' folder is visible / added to MyDrive.\"\n","    )\n","\n","MM_FULL_PATH = mm_full_matches[0]\n","EMBEDDINGS_DIR = os.path.dirname(MM_FULL_PATH)\n","\n","print(\"\\nUsing EMBEDDINGS_DIR:\", EMBEDDINGS_DIR)\n","print(\"Using MM_FULL_PATH:\", MM_FULL_PATH)\n","\n","# Quick sanity check\n","#tmp = torch.load(MM_FULL_PATH, map_location=\"cpu\")\n","#print(\"\\nMultimodal FULL dataset splits:\", tmp.keys())\n","#print(\"Metadata:\", tmp.get(\"metadata\", {}))\n","#del tmp\n"]},{"cell_type":"code","source":["# ==== Load IU X-Ray text data (sample_data.csv or processed_data.csv) ====\n","import pandas as pd\n","\n","if USE_SAMPLE_TEXT:\n","    csv_path = os.path.join(BASE_DIR, \"sample_data.csv\")\n","else:\n","    csv_path = os.path.join(BASE_DIR, \"processed_data.csv\")\n","\n","print(\"Using CSV:\", csv_path)\n","df = pd.read_csv(csv_path)\n","\n","print(\"Columns:\", list(df.columns))\n","print(df.head())\n","\n","# Build a combined text field: <FINDINGS> ... <IMPRESSION> ...\n","def build_report(row):\n","    f = str(row.get(\"findings_final\", \"\")).strip()\n","    i = str(row.get(\"impression_final\", \"\")).strip()\n","    parts = []\n","    if f:\n","        parts.append(\"<FINDINGS> \" + f)\n","    if i:\n","        parts.append(\"<IMPRESSION> \" + i)\n","    return \" \".join(parts)\n","\n","df[\"report_text\"] = df.apply(build_report, axis=1)\n","\n","# Drop rows with empty text\n","df = df[df[\"report_text\"].str.strip().astype(bool)].reset_index(drop=True)\n","print(\"\\nAfter building report_text, total rows:\", len(df))\n","print(df[[\"uid\", \"filename\", \"report_text\"]].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgA7XdatrkW6","executionInfo":{"status":"ok","timestamp":1764726658446,"user_tz":300,"elapsed":899,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"67f37a58-067f-42c7-b274-7e5300a2049e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CSV: /content/drive/MyDrive/processed data/data/data/processed_data.csv\n","Columns: ['uid', 'filename', 'projection', 'findings_final', 'impression_final', 'full_report', 'findings_len', 'impression_len', 'full_report_len', 'MeSH', 'Problems', 'split']\n","   uid                filename projection  \\\n","0    1  1_IM-0001-4001.dcm.png    Frontal   \n","1    1  1_IM-0001-3001.dcm.png    Lateral   \n","2    2  2_IM-0652-1001.dcm.png    Frontal   \n","3    2  2_IM-0652-2001.dcm.png    Lateral   \n","4    3  3_IM-1384-1001.dcm.png    Frontal   \n","\n","                                      findings_final  \\\n","0  The cardiac silhouette and mediastinum size ar...   \n","1  The cardiac silhouette and mediastinum size ar...   \n","2  Borderline cardiomegaly. Midline sternotomy . ...   \n","3  Borderline cardiomegaly. Midline sternotomy . ...   \n","4                                             normal   \n","\n","                                    impression_final  \\\n","0                                   Normal chest x-.   \n","1                                   Normal chest x-.   \n","2                       No acute pulmonary findings.   \n","3                       No acute pulmonary findings.   \n","4  No displaced rib fractures, pneumothorax, or p...   \n","\n","                                         full_report  findings_len  \\\n","0  Indication: Positive TB test Comparison: None....           205   \n","1  Indication: Positive TB test Comparison: None....           205   \n","2  Indication: Preop bariatric surgery. Compariso...            98   \n","3  Indication: Preop bariatric surgery. Compariso...            98   \n","4  Indication: rib pain after a , steps this . Pa...             6   \n","\n","   impression_len  full_report_len  \\\n","0              16              291   \n","1              16              291   \n","2              28              204   \n","3              28              204   \n","4             195              332   \n","\n","                                                MeSH  \\\n","0                                             normal   \n","1                                             normal   \n","2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n","3  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n","4                                             normal   \n","\n","                        Problems  split  \n","0                         normal  train  \n","1                         normal  train  \n","2  Cardiomegaly;Pulmonary Artery   test  \n","3  Cardiomegaly;Pulmonary Artery   test  \n","4                         normal  train  \n","\n","After building report_text, total rows: 7466\n","   uid                filename  \\\n","0    1  1_IM-0001-4001.dcm.png   \n","1    1  1_IM-0001-3001.dcm.png   \n","2    2  2_IM-0652-1001.dcm.png   \n","3    2  2_IM-0652-2001.dcm.png   \n","4    3  3_IM-1384-1001.dcm.png   \n","\n","                                         report_text  \n","0  <FINDINGS> The cardiac silhouette and mediasti...  \n","1  <FINDINGS> The cardiac silhouette and mediasti...  \n","2  <FINDINGS> Borderline cardiomegaly. Midline st...  \n","3  <FINDINGS> Borderline cardiomegaly. Midline st...  \n","4  <FINDINGS> normal <IMPRESSION> No displaced ri...  \n"]}]},{"cell_type":"code","source":["# ==== Train/val/test split using 'split' column and wrap into HF Datasets ====\n","from datasets import Dataset, DatasetDict\n","\n","if \"split\" not in df.columns:\n","    raise ValueError(\"Expected a 'split' column in the CSV (train/val/test).\")\n","\n","train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n","val_df   = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n","test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n","\n","print(\"Full sizes -> train/val/test:\", len(train_df), len(val_df), len(test_df))\n","\n","# For Colab debugging, optionally limit sample sizes even on full CSV\n","if USE_SAMPLE_TEXT:\n","    # small sample only uses what's in sample_data.csv, so just keep everything there\n","    pass\n","else:\n","    # If you want to subsample for quick runs, uncomment:\n","    # train_df = train_df.sample(n=min(len(train_df), 2000), random_state=42).reset_index(drop=True)\n","    # val_df   = val_df.sample(n=min(len(val_df),  250), random_state=42).reset_index(drop=True)\n","    # test_df  = test_df.sample(n=min(len(test_df), 250), random_state=42).reset_index(drop=True)\n","    pass\n","\n","print(\"Using sizes -> train/val/test:\", len(train_df), len(val_df), len(test_df))\n","\n","ds_train = Dataset.from_pandas(train_df[[\"report_text\"]])\n","ds_val   = Dataset.from_pandas(val_df[[\"report_text\"]])\n","ds_test  = Dataset.from_pandas(test_df[[\"report_text\"]])\n","\n","text_ds = DatasetDict(\n","    train=ds_train,\n","    validation=ds_val,\n","    test=ds_test,\n",")\n","\n","print(text_ds)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ys7N_-OksUPy","executionInfo":{"status":"ok","timestamp":1764726658527,"user_tz":300,"elapsed":78,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"a8ab1dba-a6b8-4cfb-f5e6-bdfc87336290"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Full sizes -> train/val/test: 5223 1122 1121\n","Using sizes -> train/val/test: 5223 1122 1121\n","DatasetDict({\n","    train: Dataset({\n","        features: ['report_text'],\n","        num_rows: 5223\n","    })\n","    validation: Dataset({\n","        features: ['report_text'],\n","        num_rows: 1122\n","    })\n","    test: Dataset({\n","        features: ['report_text'],\n","        num_rows: 1121\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# ==== Initialize GPT-2 tokenizer with medical special tokens ====\n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","# Special tokens for our task\n","special_tokens = {\n","    \"bos_token\": \"<BOS>\",\n","    \"eos_token\": \"<EOS>\",\n","    \"pad_token\": \"<PAD>\",\n","    \"additional_special_tokens\": [\"<FINDINGS>\", \"<IMPRESSION>\"],\n","}\n","\n","tokenizer.add_special_tokens(special_tokens)\n","print(\"Special tokens map:\", tokenizer.special_tokens_map)\n","\n","# Some core medical terms to add to vocab\n","MED_TOKENS = [\n","    \"cardiomegaly\", \"atelectasis\", \"consolidation\", \"effusion\", \"pneumothorax\",\n","    \"edema\", \"collapse\", \"opacity\", \"opacities\", \"hyperinflation\", \"fibrosis\",\n","    \"infiltrate\", \"infiltrates\", \"pleural\", \"interstitial\"\n","]\n","\n","added = tokenizer.add_tokens(MED_TOKENS)\n","print(f\"Added medical tokens: {added}\")\n","print(\"New vocab size:\", len(tokenizer))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmbRHacYsbqi","executionInfo":{"status":"ok","timestamp":1764726659288,"user_tz":300,"elapsed":760,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"552da4f9-4604-4b19-fb64-3bf6faf4c06e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Special tokens map: {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<FINDINGS>', '<IMPRESSION>']}\n","Added medical tokens: 15\n","New vocab size: 50276\n"]}]},{"cell_type":"code","source":["# ==== Load GPT-2 model and resize embeddings for new tokens ====\n","from transformers import AutoModelForCausalLM\n","\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Set BOS/EOS/PAD IDs\n","model.config.bos_token_id = tokenizer.bos_token_id\n","model.config.eos_token_id = tokenizer.eos_token_id\n","model.config.pad_token_id = tokenizer.pad_token_id\n","\n","model = model.to(device)\n","print(\"bos_token_id:\", model.config.bos_token_id)\n","print(\"eos_token_id:\", model.config.eos_token_id)\n","print(\"pad_token_id:\", model.config.pad_token_id)\n","print(\"Hidden size:\", model.config.n_embd)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1lJV0ww0uBW9","executionInfo":{"status":"ok","timestamp":1764726660412,"user_tz":300,"elapsed":1121,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"52b0c017-4a61-4ff0-c7b3-f49cdc356a6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"output_type":"stream","name":"stdout","text":["bos_token_id: 50257\n","eos_token_id: 50258\n","pad_token_id: 50259\n","Hidden size: 768\n"]}]},{"cell_type":"code","source":["# ==== Tokenize text dataset for Causal LM ====\n","def tokenize_function(batch):\n","    texts = batch[\"report_text\"]\n","    encoded = tokenizer(\n","        [tokenizer.bos_token + \" \" + t for t in texts],\n","        truncation=True,\n","        max_length=TEXT_MAX_LENGTH,\n","        return_attention_mask=True,\n","    )\n","    return encoded\n","\n","tokenized_text_ds = text_ds.map(tokenize_function, batched=True, remove_columns=[\"report_text\"])\n","\n","# For causal LM, labels = input_ids\n","def add_labels(batch):\n","    batch[\"labels\"] = batch[\"input_ids\"].copy()\n","    return batch\n","\n","tokenized_text_ds = tokenized_text_ds.map(add_labels, batched=True)\n","\n","print(tokenized_text_ds)\n"],"metadata":{"id":"F2BqOryluEMr","colab":{"base_uri":"https://localhost:8080/","height":452,"referenced_widgets":["05a4f9bf3b3144618d2eb6d2db11b464","a6bebf809a52492dac40b4dd8078dc5a","b1463f76a44c49ea80eef51e1af618a7","5988a7a1faea4a95963141b5fa510af0","66b269fe193344d18bbbf004d2e74f98","a61bc0f75e9849d5b9dfe59f440b4150","589116bfd026426f8f738c4c913ee284","4333a29d8ed94c8fb352c1815e4a2a86","fe8a307e688e457aad8998be63f595ce","88addf25875c4920871837871489d4fd","c7faa6c5ac5e439bbaf3712313df3a7d","b4ca2f0c11db4a9086355415b74efeeb","366c147b930e4b10be79c0693da12553","21d7c7be2ca54a7ba2d5fdb7bb1f74da","130a299472c641a1bf3018724aa2a4b4","2089f692f97f4716a292346d963cc80a","7a257742175a4a8f934b78ea21fa796e","75c833a24589480aa8ff576b77054e8c","1d58f45aea30433e8240980aa2e0266e","7e8ab10427ac4ca3b72558ce825c2dd9","301700abd7184036be76108141bec125","ac327a6bc8294c4d86b01e1845c1d43a","c29c12ccb4f24268828ccbbcb738f0cb","bf109e5b50374890a9178b75ea380133","cda8bd8077924f1e9ea6f9d97847649b","e70d858da4ef480997491a803b563eec","cde0d8b37afa458092ff438955177a93","de0b25669c00450d97eb4d4dfb10c809","3e835dce24da41818b3bfed6b9dd98b7","68bc9fe9f3a2439180364934d8dabbd8","d2b127e60b4e449e84a2e7ca213e55c3","588cf043c6e64bef83c312d327cfe0a5","dadded5ccab74e3ca2f57206b7c0a38f","7122524388944cf5865028133cfc34d3","8c6730424310447f9ec427c548dcb63a","424385b100d94773b379e00adb02f02a","573f467e4c8c41cb91e9c0c6de960978","4e55002e3e174980889522d98d14aa97","35bc03fabad6495aa1aebf1fd3b2dc20","7f1ee6d8747e428b96a042e4c56ff6c0","a7cb7173becf41a2b2b413fd14cdcdf3","1236c23fa0c74d60be803cd951b4b9a0","7c2d413dd1614071b7f03110febe6a32","6bdf2494640f47759695b1be32362632","f4ed0a336c144cb085b71a9269524a1d","db34a1eff03742fc9703f1cd270f47bb","d436f4ffdd9042fb864d3ffb4e7de7d4","45360639d26946fd8e4bdde5753fdd46","19f305cae7a94e2fabb269261d9a5dbc","6850c4039b5d466182ccae45f5520027","786c936d8eb249a1b0d72463c7575da0","cdf8387b82e247f7a810619e82b75843","8f5de1398a924ad99c3a41580d67e2ea","4a933492a89a4e86ae7ba0325e45bbfe","29f2ae9b070842bf8cf9a57e403fec33","ee8d4ae62e574ed1930fba11f3a97aec","f92b660acb6c4eca9cfa853f875459b0","0b4d7675ec3c4f3690525ae8db50a721","4ea7af8b13ce4f2ea23cbb4c43a07097","5bccfbff6d0f420d9f1c27fc6c3b21ee","d06ecb2803804d0cb3c875254b919a31","bf3a2d5e1d164ff29744a0933f85aa5b","661224461e664c1ba62df50239ec7440","dc143a50be174e27973891871f5042bb","58845df187d34ed3bd2c4f991dbccc3d","6f3e62aa521440389fe49f6dafd7ac77"]},"executionInfo":{"status":"ok","timestamp":1764726661783,"user_tz":300,"elapsed":1369,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"c765779e-ee34-4604-e4b9-959db3a56cdc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5223 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a4f9bf3b3144618d2eb6d2db11b464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1122 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ca2f0c11db4a9086355415b74efeeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1121 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29c12ccb4f24268828ccbbcb738f0cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5223 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7122524388944cf5865028133cfc34d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1122 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4ed0a336c144cb085b71a9269524a1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1121 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee8d4ae62e574ed1930fba11f3a97aec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 5223\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1122\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1121\n","    })\n","})\n"]}]},{"cell_type":"code","source":["# ==== Rebuild tokenized dataset + train text-only GPT-2 decoder (fixed) ====\n","from datasets import DatasetDict\n","from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","from collections import defaultdict\n","import math\n","import os\n","\n","# 1) Rebuild tokenized_text_ds cleanly (no manual labels)\n","def tokenize_for_lm(batch):\n","    texts = batch[\"report_text\"]\n","    encoded = tokenizer(\n","        [tokenizer.bos_token + \" \" + t for t in texts],\n","        truncation=True,\n","        max_length=TEXT_MAX_LENGTH,\n","        return_attention_mask=True,\n","        padding=False,   # leave ragged; collator will pad per batch\n","    )\n","    return encoded\n","\n","tokenized_text_ds = text_ds.map(\n","    tokenize_for_lm,\n","    batched=True,\n","    remove_columns=[\"report_text\"],  # keep only token ids & masks\n",")\n","\n","print(\"Tokenized dataset:\")\n","print(tokenized_text_ds)\n","for split in tokenized_text_ds:\n","    print(split, tokenized_text_ds[split][0])\n","\n","# 2) Data collator: will create labels = input_ids and pad batch\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False,   # causal LM\n",")\n","\n","# 3) Output dirs depend on whether we are using sample or full dataset\n","if USE_SAMPLE_TEXT:\n","    DECODER_TOKENIZER_DIR = os.path.join(BASE_DIR, \"sample_decoder_tokenizer\")\n","    DECODER_PRETRAINED_DIR = os.path.join(BASE_DIR, \"sample_decoder_pretrained\")\n","else:\n","    DECODER_TOKENIZER_DIR = os.path.join(BASE_DIR, \"decoder_tokenizer\")\n","    DECODER_PRETRAINED_DIR = os.path.join(BASE_DIR, \"decoder_pretrained\")\n","\n","os.makedirs(DECODER_TOKENIZER_DIR, exist_ok=True)\n","os.makedirs(DECODER_PRETRAINED_DIR, exist_ok=True)\n","\n","print(\"Decoder tokenizer dir:\", DECODER_TOKENIZER_DIR)\n","print(\"Decoder model dir:\", DECODER_PRETRAINED_DIR)\n","\n","# 4) TrainingArguments + Trainer\n","training_args = TrainingArguments(\n","    output_dir=DECODER_PRETRAINED_DIR,\n","    per_device_train_batch_size=TEXT_TRAIN_BS,\n","    per_device_eval_batch_size=TEXT_EVAL_BS,\n","    gradient_accumulation_steps=TEXT_GRAD_ACCUM,\n","    num_train_epochs=TEXT_NUM_EPOCHS,\n","    learning_rate=TEXT_LR,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    logging_steps=50,\n","    fp16=True if device == \"cuda\" else False,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_text_ds[\"train\"],\n","    eval_dataset=tokenized_text_ds[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")\n","\n","# 5) Train\n","trainer.train()\n","\n","# 6) Regular eval + perplexity\n","eval_results = trainer.evaluate()\n","print(eval_results)\n","\n","if \"eval_loss\" in eval_results:\n","    perplexity = math.exp(eval_results[\"eval_loss\"])\n","    print(\"Validation Perplexity (text-only decoder):\", perplexity)\n","else:\n","    print(\"No eval_loss found.\")\n","\n","# 7) Epoch-level summary\n","epoch_train_losses = defaultdict(list)\n","epoch_eval_losses = defaultdict(list)\n","\n","for entry in trainer.state.log_history:\n","    if \"loss\" in entry and \"epoch\" in entry and \"eval_loss\" not in entry:\n","        epoch_train_losses[entry[\"epoch\"]].append(entry[\"loss\"])\n","    if \"eval_loss\" in entry and \"epoch\" in entry:\n","        epoch_eval_losses[entry[\"epoch\"]].append(entry[\"eval_loss\"])\n","\n","print(\"\\nEpoch | Train loss | Eval loss\")\n","print(\"------|-----------|----------\")\n","all_epochs = sorted(set(list(epoch_train_losses.keys()) + list(epoch_eval_losses.keys())))\n","for ep in all_epochs:\n","    train_loss = epoch_train_losses[ep][-1] if ep in epoch_train_losses else None\n","    eval_loss = epoch_eval_losses[ep][-1] if ep in epoch_eval_losses else None\n","    t_str = f\"{train_loss:.4f}\" if train_loss is not None else \"   -   \"\n","    e_str = f\"{eval_loss:.4f}\" if eval_loss is not None else \"   -   \"\n","    print(f\"{ep:5.1f} | {t_str:9} | {e_str}\")\n"],"metadata":{"id":"zrXvo3-2uS-y","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c9dd70b73e3a477ca7610fe925ca5d42","c3bed9230ca24b1d913abf032b5ffd1a","f296887a595a44f88e45b4208673bb8b","435234221bee4c47adce3d5ed49c9c6b","6c4628dce9814c00a79e2a1cca00ccf3","0f5b3f719bca416c9f620ed04f9dba20","3aed5bde04204bf6b42eb9f8cea0ccb2","85cf42d6d14e489fa8985b0df3d87d53","1886e78e2ae14a108bf2692ba810e7aa","f4cfd7f8d39b45a68c54eec2ba283607","4d74c2f17ec341e8b3f32c11aea560e5","afc1ed05e3e04e568349db2c7413a2bc","020e7877262741518c2cdecdf32a6dfe","c33c38997fe44492aaa1c32028198c4c","77069d34dd4645699066123136a55e65","c34bf70d0883487089c8f33a4ed31614","671ca49dfe964bbabb04d40417e4653e","b1e28242b95c46418c46fc179e44ff72","9a283e911c4441e592f12591124ac2c1","6835f5daa92a40b3ad8f7c799aea5a01","14e159a47df74a3ebafb4404f2cf522d","c240b1fb51fa481093874680361a2d07","749367b963c1412f95e83c7c3dcf8ab5","c84ec90234184a74b5ef4d9ea9a69c17","1cbd79030b32410988c03c44caf2295f","a59611236cba49c383d78f731347bdb0","61d7a2865e744e3da8c0c99b188cb709","1c1f7a56737f489ba32d6a3b4fc0c475","f183c447d17e49f8befb9c8bb5b57e01","c8a6ffd2064c4d528aa11d436b17ef52","25442bdcc11e49e18b2378eedc0bd29a","3493c4c20e78417a8db91afa05049330","737ad2cce8bc4243a142699aaeeeb564"]},"executionInfo":{"status":"ok","timestamp":1764726831234,"user_tz":300,"elapsed":169419,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"25740d9c-487c-4c70-edd5-ba9f8c30bf3e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5223 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dd70b73e3a477ca7610fe925ca5d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1122 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc1ed05e3e04e568349db2c7413a2bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1121 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"749367b963c1412f95e83c7c3dcf8ab5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenized dataset:\n","DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 5223\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 1122\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 1121\n","    })\n","})\n","train {'input_ids': [50257, 220, 50260, 383, 26077, 41834, 290, 16957, 459, 259, 388, 2546, 389, 1626, 3487, 7095, 13, 1318, 318, 645, 45105, 220, 50267, 13, 1318, 318, 645, 25397, 220, 50264, 13, 1318, 389, 645, 286, 257, 220, 50275, 220, 50265, 13, 1318, 318, 645, 2370, 286, 220, 50266, 13, 220, 50261, 14435, 7721, 2124, 34507], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","validation {'input_ids': [50257, 220, 50260, 1318, 389, 42864, 24537, 220, 29446, 290, 435, 303, 6192, 220, 50270, 6414, 351, 10726, 26520, 425, 12317, 4369, 290, 6473, 516, 795, 6883, 325, 2611, 13, 1318, 389, 21388, 220, 50270, 287, 262, 1364, 12317, 40167, 11, 326, 714, 2380, 257, 22357, 9331, 10287, 295, 287, 262, 1364, 12317, 40167, 13, 1858, 389, 15113, 88, 220, 50270, 287, 262, 826, 6727, 49918, 11, 10153, 1806, 13, 383, 2657, 72, 12657, 72, 459, 1292, 41834, 318, 3487, 287, 2546, 290, 542, 454, 13, 1318, 318, 645, 220, 50266, 393, 1588, 220, 50275, 220, 50265, 13, 220, 50261, 352, 13, 8266, 516, 795, 6883, 325, 2611, 290, 220, 29446, 220, 50272, 13, 362, 13, 18578, 10153, 1806, 287, 262, 1364, 40167, 11, 3584, 2408, 284, 19607, 257, 22357, 9331, 10287, 295, 13, 513, 13, 8670, 330, 871, 287, 262, 24537, 6727, 6804, 274, 714, 2380, 10153, 1806, 11, 2158, 262, 8889, 286, 7208, 2814, 11, 4313, 1790, 16654, 1061, 929, 19772, 2384, 393, 16356, 41899, 897, 284, 3188, 6323, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","test {'input_ids': [50257, 220, 50260, 15443, 1370, 220, 50262, 13, 7215, 1370, 26370, 38385, 764, 2039, 15521, 276, 45105, 45894, 13, 11459, 21726, 13, 554, 2232, 1504, 764, 220, 50261, 1400, 14352, 45105, 6373, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","Decoder tokenizer dir: /content/drive/MyDrive/processed data/data/data/decoder_tokenizer\n","Decoder model dir: /content/drive/MyDrive/processed data/data/data/decoder_pretrained\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3707615095.py:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 50258, 'bos_token_id': 50257, 'pad_token_id': 50259}.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnir64\u001b[0m (\u001b[33mnir64-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.23.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251203_015105-9msm2rqr</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/nir64-university-of-maryland/huggingface/runs/9msm2rqr' target=\"_blank\">dashing-sound-12</a></strong> to <a href='https://wandb.ai/nir64-university-of-maryland/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/nir64-university-of-maryland/huggingface' target=\"_blank\">https://wandb.ai/nir64-university-of-maryland/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/nir64-university-of-maryland/huggingface/runs/9msm2rqr' target=\"_blank\">https://wandb.ai/nir64-university-of-maryland/huggingface/runs/9msm2rqr</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [820/820 02:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>4.330000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.543100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.965900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.720600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.538800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.494400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.367400</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.308300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.244200</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.253400</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.165700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.169000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.180400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.146500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.113100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.121100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [141/141 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 1.1988717317581177, 'eval_runtime': 2.9917, 'eval_samples_per_second': 375.039, 'eval_steps_per_second': 47.131, 'epoch': 5.0}\n","Validation Perplexity (text-only decoder): 3.316373052695281\n","\n","Epoch | Train loss | Eval loss\n","------|-----------|----------\n","  0.3 | 4.3300    |    -   \n","  0.6 | 2.5431    |    -   \n","  0.9 | 1.9659    |    -   \n","  1.2 | 1.7206    |    -   \n","  1.5 | 1.5388    |    -   \n","  1.8 | 1.4944    |    -   \n","  2.1 | 1.3674    |    -   \n","  2.4 | 1.3083    |    -   \n","  2.7 | 1.2442    |    -   \n","  3.0 | 1.2534    |    -   \n","  3.4 | 1.1657    |    -   \n","  3.7 | 1.1690    |    -   \n","  4.0 | 1.1804    |    -   \n","  4.3 | 1.1465    |    -   \n","  4.6 | 1.1131    |    -   \n","  4.9 | 1.1211    |    -   \n","  5.0 |    -      | 1.1989\n"]}]},{"cell_type":"code","source":["# ==== Save tokenizer + text-only decoder weights ====\n","tokenizer.save_pretrained(DECODER_TOKENIZER_DIR)\n","trainer.save_model(DECODER_PRETRAINED_DIR)\n","\n","print(\"Saved tokenizer to:\", DECODER_TOKENIZER_DIR)\n","print(\"Saved text decoder model to:\", DECODER_PRETRAINED_DIR)\n"],"metadata":{"id":"UDSidqfmvm5s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764726832916,"user_tz":300,"elapsed":1673,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"c1efc60b-8669-41ac-dbfd-f7e72e77edf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved tokenizer to: /content/drive/MyDrive/processed data/data/data/decoder_tokenizer\n","Saved text decoder model to: /content/drive/MyDrive/processed data/data/data/decoder_pretrained\n"]}]},{"cell_type":"markdown","source":["# ..."],"metadata":{"id":"qBSYbxltvyln"}},{"cell_type":"code","source":["# ==== Load multimodal_dataset_full.pt and inspect ====\n","mm_data_full = torch.load(MM_FULL_PATH, map_location=\"cpu\")\n","\n","print(\"Multimodal full dataset splits:\", mm_data_full.keys())\n","print(\"Metadata:\", mm_data_full.get(\"metadata\", {}))\n","\n","example = mm_data_full[\"train\"][0]\n","print(\"\\nExample train sample keys:\", example.keys())\n","print(\"Image embedding shape:\", example[\"image_emb\"].shape)\n","print(\"Text embedding shape:\", example[\"text_emb\"].shape)\n","print(\"\\nExample impression:\", example[\"impression\"])\n","print(\"\\nExample full_report snippet:\\n\", example[\"full_report\"][:300], \"...\")\n"],"metadata":{"id":"KXu_J-Xwvq-X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764726838592,"user_tz":300,"elapsed":5675,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"fa68a00e-e927-4910-a59a-b16490fea637"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Multimodal full dataset splits: dict_keys(['train', 'val', 'test', 'metadata'])\n","Metadata: {'creation_date': '2025-12-02 23:01:23', 'vision_model': 'google/vit-base-patch16-224', 'text_model': 'emilyalsentzer/Bio_ClinicalBERT', 'image_embedding_shape': [197, 768], 'text_embedding_shape': [768], 'splits': {'train': {'num_samples': 5223, 'image_embedding_shape': [197, 768], 'text_embedding_shape': [768]}, 'val': {'num_samples': 1122, 'image_embedding_shape': [197, 768], 'text_embedding_shape': [768]}, 'test': {'num_samples': 1121, 'image_embedding_shape': [197, 768], 'text_embedding_shape': [768]}}}\n","\n","Example train sample keys: dict_keys(['filename', 'image_emb', 'text_emb', 'impression', 'full_report', 'mesh', 'problems', 'projection'])\n","Image embedding shape: torch.Size([197, 768])\n","Text embedding shape: torch.Size([768])\n","\n","Example impression: Normal chest x-.\n","\n","Example full_report snippet:\n"," Indication: Positive TB test Comparison: None. Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no of a pleural effusion. There is no evidence of pneumothorax. Impression: Normal chest x-. ...\n"]}]},{"cell_type":"code","source":["# ==== Build multimodal dataset (ViT + ClinicalBERT → condition vector) ====\n","from torch.utils.data import Dataset\n","\n","class MultimodalReportDataset(Dataset):\n","    def __init__(self, samples, tokenizer, max_length=256):\n","        self.samples = samples\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        s = self.samples[idx]\n","        # Prefer full_report; fallback to impression if needed\n","        text = s.get(\"full_report\", \"\") or s.get(\"impression\", \"\") or \"\"\n","        text = str(text)\n","\n","        prompt = (self.tokenizer.bos_token + \" \" + text).strip()\n","\n","        encoded = self.tokenizer(\n","            prompt,\n","            truncation=True,\n","            max_length=self.max_length,\n","            return_tensors=\"pt\"\n","        )\n","\n","        input_ids = encoded[\"input_ids\"][0]\n","        attention_mask = encoded[\"attention_mask\"][0]\n","        labels = input_ids.clone()\n","\n","        # Condition vector: mean ViT patch embedding + ClinicalBERT embedding\n","        img_emb = s[\"image_emb\"]              # (197, 768)\n","        txt_emb = s[\"text_emb\"]               # (768,)\n","        img_pooled = img_emb.mean(dim=0)      # (768,)\n","        cond_vec = torch.cat([img_pooled, txt_emb], dim=-1)  # (1536,)\n","\n","        return {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": labels,\n","            \"cond_vec\": cond_vec,\n","        }\n","\n","# Optionally subsample for Colab; on Zaratan set MAX_TRAIN_MM / MAX_VAL_MM = None\n","train_samples_mm = mm_data_full[\"train\"]\n","val_samples_mm   = mm_data_full[\"val\"]\n","\n","if MAX_TRAIN_MM is not None:\n","    train_samples_mm = train_samples_mm[:MAX_TRAIN_MM]\n","if MAX_VAL_MM is not None:\n","    val_samples_mm   = val_samples_mm[:MAX_VAL_MM]\n","\n","mm_train_ds = MultimodalReportDataset(train_samples_mm, tokenizer, max_length=MM_MAX_LENGTH)\n","mm_val_ds   = MultimodalReportDataset(val_samples_mm,   tokenizer, max_length=MM_MAX_LENGTH)\n","\n","print(\"Multimodal train size:\", len(mm_train_ds))\n","print(\"Multimodal val size:\", len(mm_val_ds))\n"],"metadata":{"id":"dYxjdZtwv2y4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764726838657,"user_tz":300,"elapsed":63,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"6fb11d87-f009-4736-dc24-44d339d89df5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Multimodal train size: 5223\n","Multimodal val size: 1122\n"]}]},{"cell_type":"code","source":["# ==== Collate function for multimodal batches ====\n","def multimodal_collate_fn(batch):\n","    input_ids = [b[\"input_ids\"] for b in batch]\n","    attention_masks = [b[\"attention_mask\"] for b in batch]\n","    labels = [b[\"labels\"] for b in batch]\n","    cond_vecs = [b[\"cond_vec\"] for b in batch]\n","\n","    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n","    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n","    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n","    cond_vecs = torch.stack(cond_vecs, dim=0)  # (B, 1536)\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": attention_masks,\n","        \"labels\": labels,\n","        \"cond_vec\": cond_vecs,\n","    }\n"],"metadata":{"id":"doZEAlGJv3mD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== Load text decoder checkpoint and wrap with conditioning ====\n","print(\"Device:\", device)\n","\n","# These must match the dirs used when training the text decoder\n","if USE_SAMPLE_TEXT:\n","    DECODER_TOKENIZER_DIR = os.path.join(BASE_DIR, \"sample_decoder_tokenizer\")\n","    DECODER_PRETRAINED_DIR = os.path.join(BASE_DIR, \"sample_decoder_pretrained\")\n","else:\n","    DECODER_TOKENIZER_DIR = os.path.join(BASE_DIR, \"decoder_tokenizer\")\n","    DECODER_PRETRAINED_DIR = os.path.join(BASE_DIR, \"decoder_pretrained\")\n","\n","print(\"Using decoder tokenizer from:\", DECODER_TOKENIZER_DIR)\n","print(\"Using decoder weights from:\", DECODER_PRETRAINED_DIR)\n","\n","tokenizer = AutoTokenizer.from_pretrained(DECODER_TOKENIZER_DIR)\n","gpt2_base = AutoModelForCausalLM.from_pretrained(DECODER_PRETRAINED_DIR).to(device)\n","\n","print(\"bos_token:\", tokenizer.bos_token)\n","print(\"eos_token:\", tokenizer.eos_token)\n","print(\"pad_token:\", tokenizer.pad_token)\n","print(\"GPT-2 hidden size:\", gpt2_base.config.n_embd)\n","\n","class GPT2WithConditioning(nn.Module):\n","    def __init__(self, base_model, cond_dim=1536):\n","        super().__init__()\n","        self.gpt2 = base_model\n","        self.cond_proj = nn.Linear(cond_dim, self.gpt2.config.n_embd)\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, cond_vec=None):\n","        # cond_vec: (B, cond_dim)\n","        cond_emb = self.cond_proj(cond_vec)    # (B, hidden)\n","        cond_emb = cond_emb.unsqueeze(1)       # (B, 1, hidden)\n","\n","        token_emb = self.gpt2.transformer.wte(input_ids)  # (B, T, hidden)\n","        inputs_embeds = torch.cat([cond_emb, token_emb], dim=1)  # (B, 1+T, hidden)\n","\n","        if attention_mask is not None:\n","            prefix_mask = torch.ones(\n","                (attention_mask.size(0), 1),\n","                dtype=attention_mask.dtype,\n","                device=attention_mask.device,\n","            )\n","            attention_mask = torch.cat([prefix_mask, attention_mask], dim=1)\n","\n","        if labels is not None:\n","            prefix_labels = -100 * torch.ones(\n","                (labels.size(0), 1),\n","                dtype=labels.dtype,\n","                device=labels.device,\n","            )\n","            labels = torch.cat([prefix_labels, labels], dim=1)\n","\n","        outputs = self.gpt2(\n","            inputs_embeds=inputs_embeds,\n","            attention_mask=attention_mask,\n","            labels=labels,\n","        )\n","        return outputs\n","\n","mm_model = GPT2WithConditioning(gpt2_base, cond_dim=COND_DIM).to(device)\n","mm_model.gpt2.config.use_cache = False\n","\n","# Untie shared weights so safetensors can save without error\n","with torch.no_grad():\n","    mm_model.gpt2.lm_head.weight = nn.Parameter(\n","        mm_model.gpt2.lm_head.weight.clone()\n","    )\n","\n","mm_model\n"],"metadata":{"id":"ZAZa0ODkv7Vx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764726839309,"user_tz":300,"elapsed":648,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"d08d3853-9e4d-4890-e651-d2988963e3a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Using decoder tokenizer from: /content/drive/MyDrive/processed data/data/data/decoder_tokenizer\n","Using decoder weights from: /content/drive/MyDrive/processed data/data/data/decoder_pretrained\n","bos_token: <BOS>\n","eos_token: <EOS>\n","pad_token: <PAD>\n","GPT-2 hidden size: 768\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2WithConditioning(\n","  (gpt2): GPT2LMHeadModel(\n","    (transformer): GPT2Model(\n","      (wte): Embedding(50276, 768)\n","      (wpe): Embedding(1024, 768)\n","      (drop): Dropout(p=0.1, inplace=False)\n","      (h): ModuleList(\n","        (0-11): 12 x GPT2Block(\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D(nf=2304, nx=768)\n","            (c_proj): Conv1D(nf=768, nx=768)\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D(nf=3072, nx=768)\n","            (c_proj): Conv1D(nf=768, nx=3072)\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (lm_head): Linear(in_features=768, out_features=50276, bias=False)\n","  )\n","  (cond_proj): Linear(in_features=1536, out_features=768, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# ==== Train multimodal decoder (encoder-conditioned GPT-2) ====\n","from transformers import TrainingArguments, Trainer\n","\n","MM_OUTPUT_DIR = os.path.join(\n","    BASE_DIR,\n","    \"sample_multimodal_decoder\" if USE_SAMPLE_TEXT else \"full_multimodal_decoder\",\n",")\n","os.makedirs(MM_OUTPUT_DIR, exist_ok=True)\n","print(\"Multimodal decoder output dir:\", MM_OUTPUT_DIR)\n","\n","mm_training_args = TrainingArguments(\n","    output_dir=MM_OUTPUT_DIR,\n","    num_train_epochs=MM_NUM_EPOCHS,\n","    per_device_train_batch_size=MM_TRAIN_BS,\n","    per_device_eval_batch_size=MM_EVAL_BS,\n","    gradient_accumulation_steps=MM_GRAD_ACCUM,\n","    learning_rate=MM_LR,\n","    warmup_steps=0,\n","    weight_decay=0.01,\n","    logging_steps=5,\n","    fp16=True if device == \"cuda\" else False,\n",")\n","\n","mm_trainer = Trainer(\n","    model=mm_model,\n","    args=mm_training_args,\n","    train_dataset=mm_train_ds,\n","    eval_dataset=mm_val_ds,\n","    tokenizer=tokenizer,\n","    data_collator=multimodal_collate_fn,\n",")\n","\n","mm_trainer.train()\n","\n","mm_eval_results = mm_trainer.evaluate()\n","print(\"Multimodal eval results:\", mm_eval_results)\n","\n","# Save core GPT-2 decoder, tokenizer, and full multimodal wrapper\n","os.makedirs(os.path.join(MM_OUTPUT_DIR, \"mm_decoder_gpt2\"), exist_ok=True)\n","os.makedirs(os.path.join(MM_OUTPUT_DIR, \"mm_decoder_tokenizer\"), exist_ok=True)\n","\n","mm_model.gpt2.save_pretrained(os.path.join(MM_OUTPUT_DIR, \"mm_decoder_gpt2\"))\n","tokenizer.save_pretrained(os.path.join(MM_OUTPUT_DIR, \"mm_decoder_tokenizer\"))\n","\n","torch.save(mm_model.state_dict(), os.path.join(MM_OUTPUT_DIR, \"mm_model_state.pt\"))\n","\n","print(\"Saved GPT-2 core, tokenizer, and multimodal wrapper to:\", MM_OUTPUT_DIR)\n"],"metadata":{"id":"CMc1gppTv-14","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1764727479513,"user_tz":300,"elapsed":640203,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"e0ef4450-7808-45d4-bf5d-6628163af8db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Multimodal decoder output dir: /content/drive/MyDrive/processed data/data/data/full_multimodal_decoder\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1992242010.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  mm_trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3270' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3270/3270 10:29, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>2.742100</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.254600</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.060800</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.971600</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.770700</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.685200</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.649500</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.630200</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>1.611500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.544100</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>1.443400</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.461800</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>1.463200</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.493400</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.397400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.678200</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>1.480500</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.307000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>1.559600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.451500</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>1.401600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.463300</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>1.395400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.417700</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>1.377500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>1.416300</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>1.410500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.330300</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>1.355800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.389100</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>1.341800</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.300400</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>1.508500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.338600</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>1.335500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.314000</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>1.378600</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.357300</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>1.362600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.324500</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>1.279700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.348600</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>1.448600</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.421300</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>1.188900</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.368500</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>1.357000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.394300</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>1.306600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.314600</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>1.324700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.294500</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>1.385500</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.308500</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>1.315900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.275500</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>1.264200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.306500</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>1.359500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.251000</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>1.317100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.197400</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>1.389900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.330000</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>1.198700</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.221100</td>\n","    </tr>\n","    <tr>\n","      <td>335</td>\n","      <td>1.377600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.219100</td>\n","    </tr>\n","    <tr>\n","      <td>345</td>\n","      <td>1.268800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.135100</td>\n","    </tr>\n","    <tr>\n","      <td>355</td>\n","      <td>1.246600</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.263100</td>\n","    </tr>\n","    <tr>\n","      <td>365</td>\n","      <td>1.216400</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.332600</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>1.307300</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.255500</td>\n","    </tr>\n","    <tr>\n","      <td>385</td>\n","      <td>1.170500</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.239200</td>\n","    </tr>\n","    <tr>\n","      <td>395</td>\n","      <td>1.184600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.079300</td>\n","    </tr>\n","    <tr>\n","      <td>405</td>\n","      <td>1.135600</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.095300</td>\n","    </tr>\n","    <tr>\n","      <td>415</td>\n","      <td>1.232000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.224600</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>1.191600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.152600</td>\n","    </tr>\n","    <tr>\n","      <td>435</td>\n","      <td>1.127300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.239500</td>\n","    </tr>\n","    <tr>\n","      <td>445</td>\n","      <td>1.139600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.246400</td>\n","    </tr>\n","    <tr>\n","      <td>455</td>\n","      <td>1.162300</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.255700</td>\n","    </tr>\n","    <tr>\n","      <td>465</td>\n","      <td>1.168400</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.141500</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>1.238100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.104500</td>\n","    </tr>\n","    <tr>\n","      <td>485</td>\n","      <td>1.186800</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.122100</td>\n","    </tr>\n","    <tr>\n","      <td>495</td>\n","      <td>1.152000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.087400</td>\n","    </tr>\n","    <tr>\n","      <td>505</td>\n","      <td>1.133800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.302100</td>\n","    </tr>\n","    <tr>\n","      <td>515</td>\n","      <td>1.181700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.173100</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>1.148300</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.197300</td>\n","    </tr>\n","    <tr>\n","      <td>535</td>\n","      <td>1.242200</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.190600</td>\n","    </tr>\n","    <tr>\n","      <td>545</td>\n","      <td>1.178000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.217900</td>\n","    </tr>\n","    <tr>\n","      <td>555</td>\n","      <td>1.344700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.219100</td>\n","    </tr>\n","    <tr>\n","      <td>565</td>\n","      <td>1.271800</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.068800</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>1.086100</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.118400</td>\n","    </tr>\n","    <tr>\n","      <td>585</td>\n","      <td>1.173100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.120100</td>\n","    </tr>\n","    <tr>\n","      <td>595</td>\n","      <td>1.149300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.136300</td>\n","    </tr>\n","    <tr>\n","      <td>605</td>\n","      <td>1.091400</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.085700</td>\n","    </tr>\n","    <tr>\n","      <td>615</td>\n","      <td>1.140200</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.141300</td>\n","    </tr>\n","    <tr>\n","      <td>625</td>\n","      <td>1.183600</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.153400</td>\n","    </tr>\n","    <tr>\n","      <td>635</td>\n","      <td>1.208100</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.037900</td>\n","    </tr>\n","    <tr>\n","      <td>645</td>\n","      <td>1.159000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.171200</td>\n","    </tr>\n","    <tr>\n","      <td>655</td>\n","      <td>1.083000</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.173000</td>\n","    </tr>\n","    <tr>\n","      <td>665</td>\n","      <td>1.058500</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>1.085400</td>\n","    </tr>\n","    <tr>\n","      <td>675</td>\n","      <td>1.233700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.087800</td>\n","    </tr>\n","    <tr>\n","      <td>685</td>\n","      <td>1.165700</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.132400</td>\n","    </tr>\n","    <tr>\n","      <td>695</td>\n","      <td>1.078300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.102900</td>\n","    </tr>\n","    <tr>\n","      <td>705</td>\n","      <td>1.177300</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>1.160800</td>\n","    </tr>\n","    <tr>\n","      <td>715</td>\n","      <td>1.152100</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.086400</td>\n","    </tr>\n","    <tr>\n","      <td>725</td>\n","      <td>1.068300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>1.055400</td>\n","    </tr>\n","    <tr>\n","      <td>735</td>\n","      <td>1.171300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>1.091800</td>\n","    </tr>\n","    <tr>\n","      <td>745</td>\n","      <td>1.152100</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.151100</td>\n","    </tr>\n","    <tr>\n","      <td>755</td>\n","      <td>1.089300</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>1.038700</td>\n","    </tr>\n","    <tr>\n","      <td>765</td>\n","      <td>1.103000</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>1.119200</td>\n","    </tr>\n","    <tr>\n","      <td>775</td>\n","      <td>1.107100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>1.083000</td>\n","    </tr>\n","    <tr>\n","      <td>785</td>\n","      <td>1.153300</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>1.085100</td>\n","    </tr>\n","    <tr>\n","      <td>795</td>\n","      <td>1.087000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.239100</td>\n","    </tr>\n","    <tr>\n","      <td>805</td>\n","      <td>1.239300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>1.142400</td>\n","    </tr>\n","    <tr>\n","      <td>815</td>\n","      <td>1.085200</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>1.026300</td>\n","    </tr>\n","    <tr>\n","      <td>825</td>\n","      <td>1.153100</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>1.103000</td>\n","    </tr>\n","    <tr>\n","      <td>835</td>\n","      <td>1.165900</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>1.027900</td>\n","    </tr>\n","    <tr>\n","      <td>845</td>\n","      <td>1.060900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.995400</td>\n","    </tr>\n","    <tr>\n","      <td>855</td>\n","      <td>1.031600</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>1.034100</td>\n","    </tr>\n","    <tr>\n","      <td>865</td>\n","      <td>1.112000</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>1.091900</td>\n","    </tr>\n","    <tr>\n","      <td>875</td>\n","      <td>1.084800</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>1.071100</td>\n","    </tr>\n","    <tr>\n","      <td>885</td>\n","      <td>1.078500</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>1.017900</td>\n","    </tr>\n","    <tr>\n","      <td>895</td>\n","      <td>1.141700</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.114800</td>\n","    </tr>\n","    <tr>\n","      <td>905</td>\n","      <td>1.141600</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>1.089300</td>\n","    </tr>\n","    <tr>\n","      <td>915</td>\n","      <td>1.094900</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>1.134500</td>\n","    </tr>\n","    <tr>\n","      <td>925</td>\n","      <td>1.048100</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>1.058300</td>\n","    </tr>\n","    <tr>\n","      <td>935</td>\n","      <td>1.268500</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>1.095500</td>\n","    </tr>\n","    <tr>\n","      <td>945</td>\n","      <td>1.104800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>1.137400</td>\n","    </tr>\n","    <tr>\n","      <td>955</td>\n","      <td>1.066800</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>1.088400</td>\n","    </tr>\n","    <tr>\n","      <td>965</td>\n","      <td>1.033400</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>1.019000</td>\n","    </tr>\n","    <tr>\n","      <td>975</td>\n","      <td>1.075300</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>1.123700</td>\n","    </tr>\n","    <tr>\n","      <td>985</td>\n","      <td>0.930600</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>1.085100</td>\n","    </tr>\n","    <tr>\n","      <td>995</td>\n","      <td>1.153400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.079600</td>\n","    </tr>\n","    <tr>\n","      <td>1005</td>\n","      <td>1.066100</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>1.082800</td>\n","    </tr>\n","    <tr>\n","      <td>1015</td>\n","      <td>1.031400</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>1.063500</td>\n","    </tr>\n","    <tr>\n","      <td>1025</td>\n","      <td>0.970100</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.955800</td>\n","    </tr>\n","    <tr>\n","      <td>1035</td>\n","      <td>0.922100</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>1.102400</td>\n","    </tr>\n","    <tr>\n","      <td>1045</td>\n","      <td>1.003300</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>1.041000</td>\n","    </tr>\n","    <tr>\n","      <td>1055</td>\n","      <td>1.187800</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>1.013900</td>\n","    </tr>\n","    <tr>\n","      <td>1065</td>\n","      <td>0.988700</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>1.051900</td>\n","    </tr>\n","    <tr>\n","      <td>1075</td>\n","      <td>0.978200</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>1.005100</td>\n","    </tr>\n","    <tr>\n","      <td>1085</td>\n","      <td>1.124700</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.990100</td>\n","    </tr>\n","    <tr>\n","      <td>1095</td>\n","      <td>1.117600</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>1.092700</td>\n","    </tr>\n","    <tr>\n","      <td>1105</td>\n","      <td>1.105200</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.973300</td>\n","    </tr>\n","    <tr>\n","      <td>1115</td>\n","      <td>1.029700</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>1.079500</td>\n","    </tr>\n","    <tr>\n","      <td>1125</td>\n","      <td>1.040600</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>1.097100</td>\n","    </tr>\n","    <tr>\n","      <td>1135</td>\n","      <td>1.084100</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>1.007700</td>\n","    </tr>\n","    <tr>\n","      <td>1145</td>\n","      <td>1.010200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>1.122200</td>\n","    </tr>\n","    <tr>\n","      <td>1155</td>\n","      <td>1.092400</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>1.035400</td>\n","    </tr>\n","    <tr>\n","      <td>1165</td>\n","      <td>1.092200</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>1.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1175</td>\n","      <td>1.043600</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>1.152300</td>\n","    </tr>\n","    <tr>\n","      <td>1185</td>\n","      <td>1.007000</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.957100</td>\n","    </tr>\n","    <tr>\n","      <td>1195</td>\n","      <td>1.010900</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.029100</td>\n","    </tr>\n","    <tr>\n","      <td>1205</td>\n","      <td>1.047900</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>1.070100</td>\n","    </tr>\n","    <tr>\n","      <td>1215</td>\n","      <td>0.990600</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>1.051400</td>\n","    </tr>\n","    <tr>\n","      <td>1225</td>\n","      <td>0.958000</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>1.080100</td>\n","    </tr>\n","    <tr>\n","      <td>1235</td>\n","      <td>1.005200</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>1.101600</td>\n","    </tr>\n","    <tr>\n","      <td>1245</td>\n","      <td>1.022000</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.943700</td>\n","    </tr>\n","    <tr>\n","      <td>1255</td>\n","      <td>1.121400</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>1.012200</td>\n","    </tr>\n","    <tr>\n","      <td>1265</td>\n","      <td>1.002800</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>1.147400</td>\n","    </tr>\n","    <tr>\n","      <td>1275</td>\n","      <td>1.124200</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>1.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1285</td>\n","      <td>1.133500</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>1.162100</td>\n","    </tr>\n","    <tr>\n","      <td>1295</td>\n","      <td>1.081100</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>1.085000</td>\n","    </tr>\n","    <tr>\n","      <td>1305</td>\n","      <td>1.184400</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>1.063400</td>\n","    </tr>\n","    <tr>\n","      <td>1315</td>\n","      <td>1.009500</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.922700</td>\n","    </tr>\n","    <tr>\n","      <td>1325</td>\n","      <td>0.958500</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>1.126700</td>\n","    </tr>\n","    <tr>\n","      <td>1335</td>\n","      <td>1.096100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>1.067100</td>\n","    </tr>\n","    <tr>\n","      <td>1345</td>\n","      <td>0.947000</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.953900</td>\n","    </tr>\n","    <tr>\n","      <td>1355</td>\n","      <td>0.929800</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>1.017200</td>\n","    </tr>\n","    <tr>\n","      <td>1365</td>\n","      <td>1.084100</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.968300</td>\n","    </tr>\n","    <tr>\n","      <td>1375</td>\n","      <td>1.017300</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.987600</td>\n","    </tr>\n","    <tr>\n","      <td>1385</td>\n","      <td>1.076900</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>1.107500</td>\n","    </tr>\n","    <tr>\n","      <td>1395</td>\n","      <td>0.997500</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.971900</td>\n","    </tr>\n","    <tr>\n","      <td>1405</td>\n","      <td>1.051500</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>1.116300</td>\n","    </tr>\n","    <tr>\n","      <td>1415</td>\n","      <td>1.062700</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>1.112600</td>\n","    </tr>\n","    <tr>\n","      <td>1425</td>\n","      <td>1.008700</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.882800</td>\n","    </tr>\n","    <tr>\n","      <td>1435</td>\n","      <td>1.032200</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.955700</td>\n","    </tr>\n","    <tr>\n","      <td>1445</td>\n","      <td>0.974600</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>1.037600</td>\n","    </tr>\n","    <tr>\n","      <td>1455</td>\n","      <td>0.873800</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.952700</td>\n","    </tr>\n","    <tr>\n","      <td>1465</td>\n","      <td>1.034300</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.936500</td>\n","    </tr>\n","    <tr>\n","      <td>1475</td>\n","      <td>1.043500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.974100</td>\n","    </tr>\n","    <tr>\n","      <td>1485</td>\n","      <td>1.042000</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>1.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1495</td>\n","      <td>1.119300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.045400</td>\n","    </tr>\n","    <tr>\n","      <td>1505</td>\n","      <td>1.102500</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>1.024800</td>\n","    </tr>\n","    <tr>\n","      <td>1515</td>\n","      <td>1.011600</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.896800</td>\n","    </tr>\n","    <tr>\n","      <td>1525</td>\n","      <td>0.974800</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.921800</td>\n","    </tr>\n","    <tr>\n","      <td>1535</td>\n","      <td>1.049100</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>1.040100</td>\n","    </tr>\n","    <tr>\n","      <td>1545</td>\n","      <td>1.059700</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.988600</td>\n","    </tr>\n","    <tr>\n","      <td>1555</td>\n","      <td>0.989100</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>1.012000</td>\n","    </tr>\n","    <tr>\n","      <td>1565</td>\n","      <td>1.035500</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.968700</td>\n","    </tr>\n","    <tr>\n","      <td>1575</td>\n","      <td>0.972500</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>1.104900</td>\n","    </tr>\n","    <tr>\n","      <td>1585</td>\n","      <td>0.973900</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>1.029200</td>\n","    </tr>\n","    <tr>\n","      <td>1595</td>\n","      <td>1.064000</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.993300</td>\n","    </tr>\n","    <tr>\n","      <td>1605</td>\n","      <td>1.039200</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>1.018000</td>\n","    </tr>\n","    <tr>\n","      <td>1615</td>\n","      <td>1.044400</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>1.041300</td>\n","    </tr>\n","    <tr>\n","      <td>1625</td>\n","      <td>0.965700</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.994500</td>\n","    </tr>\n","    <tr>\n","      <td>1635</td>\n","      <td>0.991900</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.967100</td>\n","    </tr>\n","    <tr>\n","      <td>1645</td>\n","      <td>0.965600</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>1.039000</td>\n","    </tr>\n","    <tr>\n","      <td>1655</td>\n","      <td>0.977000</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.989500</td>\n","    </tr>\n","    <tr>\n","      <td>1665</td>\n","      <td>0.982000</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.952300</td>\n","    </tr>\n","    <tr>\n","      <td>1675</td>\n","      <td>0.974300</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.979700</td>\n","    </tr>\n","    <tr>\n","      <td>1685</td>\n","      <td>1.038500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.936600</td>\n","    </tr>\n","    <tr>\n","      <td>1695</td>\n","      <td>0.997100</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>1.002400</td>\n","    </tr>\n","    <tr>\n","      <td>1705</td>\n","      <td>1.032400</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>1.021700</td>\n","    </tr>\n","    <tr>\n","      <td>1715</td>\n","      <td>0.998600</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>1.022900</td>\n","    </tr>\n","    <tr>\n","      <td>1725</td>\n","      <td>0.930200</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.963700</td>\n","    </tr>\n","    <tr>\n","      <td>1735</td>\n","      <td>0.980000</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>1.004300</td>\n","    </tr>\n","    <tr>\n","      <td>1745</td>\n","      <td>0.975600</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.960100</td>\n","    </tr>\n","    <tr>\n","      <td>1755</td>\n","      <td>0.879000</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>1.006000</td>\n","    </tr>\n","    <tr>\n","      <td>1765</td>\n","      <td>1.029900</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>1.027000</td>\n","    </tr>\n","    <tr>\n","      <td>1775</td>\n","      <td>0.969200</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.946100</td>\n","    </tr>\n","    <tr>\n","      <td>1785</td>\n","      <td>0.985200</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.969600</td>\n","    </tr>\n","    <tr>\n","      <td>1795</td>\n","      <td>1.051800</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.944000</td>\n","    </tr>\n","    <tr>\n","      <td>1805</td>\n","      <td>0.953900</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.937700</td>\n","    </tr>\n","    <tr>\n","      <td>1815</td>\n","      <td>1.073800</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.961000</td>\n","    </tr>\n","    <tr>\n","      <td>1825</td>\n","      <td>0.929200</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.969500</td>\n","    </tr>\n","    <tr>\n","      <td>1835</td>\n","      <td>0.930400</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>1.062300</td>\n","    </tr>\n","    <tr>\n","      <td>1845</td>\n","      <td>1.005600</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>1.008900</td>\n","    </tr>\n","    <tr>\n","      <td>1855</td>\n","      <td>1.022000</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.971200</td>\n","    </tr>\n","    <tr>\n","      <td>1865</td>\n","      <td>0.895100</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.869700</td>\n","    </tr>\n","    <tr>\n","      <td>1875</td>\n","      <td>0.949600</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.934800</td>\n","    </tr>\n","    <tr>\n","      <td>1885</td>\n","      <td>0.883600</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>1.006200</td>\n","    </tr>\n","    <tr>\n","      <td>1895</td>\n","      <td>0.905000</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>1.023200</td>\n","    </tr>\n","    <tr>\n","      <td>1905</td>\n","      <td>1.000800</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>1.018100</td>\n","    </tr>\n","    <tr>\n","      <td>1915</td>\n","      <td>0.977200</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>1.031800</td>\n","    </tr>\n","    <tr>\n","      <td>1925</td>\n","      <td>0.970300</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.971200</td>\n","    </tr>\n","    <tr>\n","      <td>1935</td>\n","      <td>0.887900</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.957600</td>\n","    </tr>\n","    <tr>\n","      <td>1945</td>\n","      <td>1.041900</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.990700</td>\n","    </tr>\n","    <tr>\n","      <td>1955</td>\n","      <td>1.031900</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.886600</td>\n","    </tr>\n","    <tr>\n","      <td>1965</td>\n","      <td>1.050600</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.964600</td>\n","    </tr>\n","    <tr>\n","      <td>1975</td>\n","      <td>0.918300</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.858000</td>\n","    </tr>\n","    <tr>\n","      <td>1985</td>\n","      <td>0.990200</td>\n","    </tr>\n","    <tr>\n","      <td>1990</td>\n","      <td>0.977600</td>\n","    </tr>\n","    <tr>\n","      <td>1995</td>\n","      <td>0.913700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.021300</td>\n","    </tr>\n","    <tr>\n","      <td>2005</td>\n","      <td>0.948700</td>\n","    </tr>\n","    <tr>\n","      <td>2010</td>\n","      <td>1.042800</td>\n","    </tr>\n","    <tr>\n","      <td>2015</td>\n","      <td>0.991300</td>\n","    </tr>\n","    <tr>\n","      <td>2020</td>\n","      <td>0.965700</td>\n","    </tr>\n","    <tr>\n","      <td>2025</td>\n","      <td>0.961500</td>\n","    </tr>\n","    <tr>\n","      <td>2030</td>\n","      <td>0.966800</td>\n","    </tr>\n","    <tr>\n","      <td>2035</td>\n","      <td>0.928500</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.955700</td>\n","    </tr>\n","    <tr>\n","      <td>2045</td>\n","      <td>0.908000</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.990300</td>\n","    </tr>\n","    <tr>\n","      <td>2055</td>\n","      <td>0.923800</td>\n","    </tr>\n","    <tr>\n","      <td>2060</td>\n","      <td>0.898400</td>\n","    </tr>\n","    <tr>\n","      <td>2065</td>\n","      <td>0.976800</td>\n","    </tr>\n","    <tr>\n","      <td>2070</td>\n","      <td>0.923000</td>\n","    </tr>\n","    <tr>\n","      <td>2075</td>\n","      <td>0.867900</td>\n","    </tr>\n","    <tr>\n","      <td>2080</td>\n","      <td>1.025700</td>\n","    </tr>\n","    <tr>\n","      <td>2085</td>\n","      <td>0.905700</td>\n","    </tr>\n","    <tr>\n","      <td>2090</td>\n","      <td>1.042800</td>\n","    </tr>\n","    <tr>\n","      <td>2095</td>\n","      <td>0.994200</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.895700</td>\n","    </tr>\n","    <tr>\n","      <td>2105</td>\n","      <td>0.962300</td>\n","    </tr>\n","    <tr>\n","      <td>2110</td>\n","      <td>0.912100</td>\n","    </tr>\n","    <tr>\n","      <td>2115</td>\n","      <td>0.950500</td>\n","    </tr>\n","    <tr>\n","      <td>2120</td>\n","      <td>0.938200</td>\n","    </tr>\n","    <tr>\n","      <td>2125</td>\n","      <td>1.067300</td>\n","    </tr>\n","    <tr>\n","      <td>2130</td>\n","      <td>0.958900</td>\n","    </tr>\n","    <tr>\n","      <td>2135</td>\n","      <td>1.005100</td>\n","    </tr>\n","    <tr>\n","      <td>2140</td>\n","      <td>0.886300</td>\n","    </tr>\n","    <tr>\n","      <td>2145</td>\n","      <td>0.921200</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.939400</td>\n","    </tr>\n","    <tr>\n","      <td>2155</td>\n","      <td>0.980000</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.956200</td>\n","    </tr>\n","    <tr>\n","      <td>2165</td>\n","      <td>0.880900</td>\n","    </tr>\n","    <tr>\n","      <td>2170</td>\n","      <td>0.900700</td>\n","    </tr>\n","    <tr>\n","      <td>2175</td>\n","      <td>0.898900</td>\n","    </tr>\n","    <tr>\n","      <td>2180</td>\n","      <td>0.869900</td>\n","    </tr>\n","    <tr>\n","      <td>2185</td>\n","      <td>0.995700</td>\n","    </tr>\n","    <tr>\n","      <td>2190</td>\n","      <td>1.005400</td>\n","    </tr>\n","    <tr>\n","      <td>2195</td>\n","      <td>0.950000</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.974100</td>\n","    </tr>\n","    <tr>\n","      <td>2205</td>\n","      <td>0.929800</td>\n","    </tr>\n","    <tr>\n","      <td>2210</td>\n","      <td>0.937300</td>\n","    </tr>\n","    <tr>\n","      <td>2215</td>\n","      <td>0.851600</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>1.012500</td>\n","    </tr>\n","    <tr>\n","      <td>2225</td>\n","      <td>0.935800</td>\n","    </tr>\n","    <tr>\n","      <td>2230</td>\n","      <td>0.953700</td>\n","    </tr>\n","    <tr>\n","      <td>2235</td>\n","      <td>0.961500</td>\n","    </tr>\n","    <tr>\n","      <td>2240</td>\n","      <td>0.942600</td>\n","    </tr>\n","    <tr>\n","      <td>2245</td>\n","      <td>1.022200</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.922900</td>\n","    </tr>\n","    <tr>\n","      <td>2255</td>\n","      <td>0.992400</td>\n","    </tr>\n","    <tr>\n","      <td>2260</td>\n","      <td>0.946000</td>\n","    </tr>\n","    <tr>\n","      <td>2265</td>\n","      <td>0.912800</td>\n","    </tr>\n","    <tr>\n","      <td>2270</td>\n","      <td>0.919700</td>\n","    </tr>\n","    <tr>\n","      <td>2275</td>\n","      <td>1.044600</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.877200</td>\n","    </tr>\n","    <tr>\n","      <td>2285</td>\n","      <td>0.929900</td>\n","    </tr>\n","    <tr>\n","      <td>2290</td>\n","      <td>0.916800</td>\n","    </tr>\n","    <tr>\n","      <td>2295</td>\n","      <td>0.957500</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.992400</td>\n","    </tr>\n","    <tr>\n","      <td>2305</td>\n","      <td>1.010000</td>\n","    </tr>\n","    <tr>\n","      <td>2310</td>\n","      <td>0.954600</td>\n","    </tr>\n","    <tr>\n","      <td>2315</td>\n","      <td>0.870100</td>\n","    </tr>\n","    <tr>\n","      <td>2320</td>\n","      <td>0.932600</td>\n","    </tr>\n","    <tr>\n","      <td>2325</td>\n","      <td>0.959100</td>\n","    </tr>\n","    <tr>\n","      <td>2330</td>\n","      <td>0.953500</td>\n","    </tr>\n","    <tr>\n","      <td>2335</td>\n","      <td>0.969800</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>1.003500</td>\n","    </tr>\n","    <tr>\n","      <td>2345</td>\n","      <td>0.943600</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.857200</td>\n","    </tr>\n","    <tr>\n","      <td>2355</td>\n","      <td>0.906600</td>\n","    </tr>\n","    <tr>\n","      <td>2360</td>\n","      <td>1.036500</td>\n","    </tr>\n","    <tr>\n","      <td>2365</td>\n","      <td>0.909100</td>\n","    </tr>\n","    <tr>\n","      <td>2370</td>\n","      <td>1.028800</td>\n","    </tr>\n","    <tr>\n","      <td>2375</td>\n","      <td>0.918900</td>\n","    </tr>\n","    <tr>\n","      <td>2380</td>\n","      <td>0.966500</td>\n","    </tr>\n","    <tr>\n","      <td>2385</td>\n","      <td>0.956200</td>\n","    </tr>\n","    <tr>\n","      <td>2390</td>\n","      <td>0.942700</td>\n","    </tr>\n","    <tr>\n","      <td>2395</td>\n","      <td>0.888000</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.948700</td>\n","    </tr>\n","    <tr>\n","      <td>2405</td>\n","      <td>0.939000</td>\n","    </tr>\n","    <tr>\n","      <td>2410</td>\n","      <td>0.906700</td>\n","    </tr>\n","    <tr>\n","      <td>2415</td>\n","      <td>0.863900</td>\n","    </tr>\n","    <tr>\n","      <td>2420</td>\n","      <td>0.898500</td>\n","    </tr>\n","    <tr>\n","      <td>2425</td>\n","      <td>0.926100</td>\n","    </tr>\n","    <tr>\n","      <td>2430</td>\n","      <td>0.902900</td>\n","    </tr>\n","    <tr>\n","      <td>2435</td>\n","      <td>1.005700</td>\n","    </tr>\n","    <tr>\n","      <td>2440</td>\n","      <td>0.881200</td>\n","    </tr>\n","    <tr>\n","      <td>2445</td>\n","      <td>0.967700</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.921000</td>\n","    </tr>\n","    <tr>\n","      <td>2455</td>\n","      <td>0.936200</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.945900</td>\n","    </tr>\n","    <tr>\n","      <td>2465</td>\n","      <td>0.921400</td>\n","    </tr>\n","    <tr>\n","      <td>2470</td>\n","      <td>0.880000</td>\n","    </tr>\n","    <tr>\n","      <td>2475</td>\n","      <td>0.870700</td>\n","    </tr>\n","    <tr>\n","      <td>2480</td>\n","      <td>0.978600</td>\n","    </tr>\n","    <tr>\n","      <td>2485</td>\n","      <td>0.934900</td>\n","    </tr>\n","    <tr>\n","      <td>2490</td>\n","      <td>0.906500</td>\n","    </tr>\n","    <tr>\n","      <td>2495</td>\n","      <td>0.995000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.952600</td>\n","    </tr>\n","    <tr>\n","      <td>2505</td>\n","      <td>0.889100</td>\n","    </tr>\n","    <tr>\n","      <td>2510</td>\n","      <td>0.888000</td>\n","    </tr>\n","    <tr>\n","      <td>2515</td>\n","      <td>0.969000</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.987400</td>\n","    </tr>\n","    <tr>\n","      <td>2525</td>\n","      <td>0.938800</td>\n","    </tr>\n","    <tr>\n","      <td>2530</td>\n","      <td>0.855500</td>\n","    </tr>\n","    <tr>\n","      <td>2535</td>\n","      <td>0.905000</td>\n","    </tr>\n","    <tr>\n","      <td>2540</td>\n","      <td>0.996600</td>\n","    </tr>\n","    <tr>\n","      <td>2545</td>\n","      <td>0.899900</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.858800</td>\n","    </tr>\n","    <tr>\n","      <td>2555</td>\n","      <td>0.883000</td>\n","    </tr>\n","    <tr>\n","      <td>2560</td>\n","      <td>0.921500</td>\n","    </tr>\n","    <tr>\n","      <td>2565</td>\n","      <td>0.788300</td>\n","    </tr>\n","    <tr>\n","      <td>2570</td>\n","      <td>0.892700</td>\n","    </tr>\n","    <tr>\n","      <td>2575</td>\n","      <td>0.896600</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.983800</td>\n","    </tr>\n","    <tr>\n","      <td>2585</td>\n","      <td>0.982000</td>\n","    </tr>\n","    <tr>\n","      <td>2590</td>\n","      <td>1.010700</td>\n","    </tr>\n","    <tr>\n","      <td>2595</td>\n","      <td>0.944400</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.865300</td>\n","    </tr>\n","    <tr>\n","      <td>2605</td>\n","      <td>0.884000</td>\n","    </tr>\n","    <tr>\n","      <td>2610</td>\n","      <td>0.897200</td>\n","    </tr>\n","    <tr>\n","      <td>2615</td>\n","      <td>0.898200</td>\n","    </tr>\n","    <tr>\n","      <td>2620</td>\n","      <td>0.973400</td>\n","    </tr>\n","    <tr>\n","      <td>2625</td>\n","      <td>0.909400</td>\n","    </tr>\n","    <tr>\n","      <td>2630</td>\n","      <td>0.891100</td>\n","    </tr>\n","    <tr>\n","      <td>2635</td>\n","      <td>0.897100</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.912100</td>\n","    </tr>\n","    <tr>\n","      <td>2645</td>\n","      <td>0.841900</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.906200</td>\n","    </tr>\n","    <tr>\n","      <td>2655</td>\n","      <td>0.904200</td>\n","    </tr>\n","    <tr>\n","      <td>2660</td>\n","      <td>0.866400</td>\n","    </tr>\n","    <tr>\n","      <td>2665</td>\n","      <td>0.970900</td>\n","    </tr>\n","    <tr>\n","      <td>2670</td>\n","      <td>0.832000</td>\n","    </tr>\n","    <tr>\n","      <td>2675</td>\n","      <td>0.884400</td>\n","    </tr>\n","    <tr>\n","      <td>2680</td>\n","      <td>0.974400</td>\n","    </tr>\n","    <tr>\n","      <td>2685</td>\n","      <td>0.891800</td>\n","    </tr>\n","    <tr>\n","      <td>2690</td>\n","      <td>0.897000</td>\n","    </tr>\n","    <tr>\n","      <td>2695</td>\n","      <td>0.856300</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.968200</td>\n","    </tr>\n","    <tr>\n","      <td>2705</td>\n","      <td>0.949900</td>\n","    </tr>\n","    <tr>\n","      <td>2710</td>\n","      <td>1.055900</td>\n","    </tr>\n","    <tr>\n","      <td>2715</td>\n","      <td>0.801700</td>\n","    </tr>\n","    <tr>\n","      <td>2720</td>\n","      <td>1.005700</td>\n","    </tr>\n","    <tr>\n","      <td>2725</td>\n","      <td>0.848700</td>\n","    </tr>\n","    <tr>\n","      <td>2730</td>\n","      <td>0.927000</td>\n","    </tr>\n","    <tr>\n","      <td>2735</td>\n","      <td>0.907400</td>\n","    </tr>\n","    <tr>\n","      <td>2740</td>\n","      <td>0.906400</td>\n","    </tr>\n","    <tr>\n","      <td>2745</td>\n","      <td>0.878000</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.901000</td>\n","    </tr>\n","    <tr>\n","      <td>2755</td>\n","      <td>0.920300</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.984100</td>\n","    </tr>\n","    <tr>\n","      <td>2765</td>\n","      <td>0.970000</td>\n","    </tr>\n","    <tr>\n","      <td>2770</td>\n","      <td>0.878600</td>\n","    </tr>\n","    <tr>\n","      <td>2775</td>\n","      <td>0.863600</td>\n","    </tr>\n","    <tr>\n","      <td>2780</td>\n","      <td>0.932400</td>\n","    </tr>\n","    <tr>\n","      <td>2785</td>\n","      <td>0.994400</td>\n","    </tr>\n","    <tr>\n","      <td>2790</td>\n","      <td>0.850400</td>\n","    </tr>\n","    <tr>\n","      <td>2795</td>\n","      <td>0.972200</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.951700</td>\n","    </tr>\n","    <tr>\n","      <td>2805</td>\n","      <td>0.866800</td>\n","    </tr>\n","    <tr>\n","      <td>2810</td>\n","      <td>0.940600</td>\n","    </tr>\n","    <tr>\n","      <td>2815</td>\n","      <td>0.933700</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.876600</td>\n","    </tr>\n","    <tr>\n","      <td>2825</td>\n","      <td>0.889600</td>\n","    </tr>\n","    <tr>\n","      <td>2830</td>\n","      <td>0.903000</td>\n","    </tr>\n","    <tr>\n","      <td>2835</td>\n","      <td>0.846100</td>\n","    </tr>\n","    <tr>\n","      <td>2840</td>\n","      <td>0.960400</td>\n","    </tr>\n","    <tr>\n","      <td>2845</td>\n","      <td>0.903600</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.892900</td>\n","    </tr>\n","    <tr>\n","      <td>2855</td>\n","      <td>0.914000</td>\n","    </tr>\n","    <tr>\n","      <td>2860</td>\n","      <td>0.993700</td>\n","    </tr>\n","    <tr>\n","      <td>2865</td>\n","      <td>0.994100</td>\n","    </tr>\n","    <tr>\n","      <td>2870</td>\n","      <td>0.964300</td>\n","    </tr>\n","    <tr>\n","      <td>2875</td>\n","      <td>0.862700</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.884200</td>\n","    </tr>\n","    <tr>\n","      <td>2885</td>\n","      <td>0.987000</td>\n","    </tr>\n","    <tr>\n","      <td>2890</td>\n","      <td>1.003500</td>\n","    </tr>\n","    <tr>\n","      <td>2895</td>\n","      <td>0.879300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.894800</td>\n","    </tr>\n","    <tr>\n","      <td>2905</td>\n","      <td>0.889700</td>\n","    </tr>\n","    <tr>\n","      <td>2910</td>\n","      <td>0.916800</td>\n","    </tr>\n","    <tr>\n","      <td>2915</td>\n","      <td>0.827200</td>\n","    </tr>\n","    <tr>\n","      <td>2920</td>\n","      <td>0.912200</td>\n","    </tr>\n","    <tr>\n","      <td>2925</td>\n","      <td>0.966300</td>\n","    </tr>\n","    <tr>\n","      <td>2930</td>\n","      <td>0.903500</td>\n","    </tr>\n","    <tr>\n","      <td>2935</td>\n","      <td>1.034900</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.890400</td>\n","    </tr>\n","    <tr>\n","      <td>2945</td>\n","      <td>0.912300</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.937400</td>\n","    </tr>\n","    <tr>\n","      <td>2955</td>\n","      <td>0.821000</td>\n","    </tr>\n","    <tr>\n","      <td>2960</td>\n","      <td>0.918300</td>\n","    </tr>\n","    <tr>\n","      <td>2965</td>\n","      <td>0.948700</td>\n","    </tr>\n","    <tr>\n","      <td>2970</td>\n","      <td>0.815400</td>\n","    </tr>\n","    <tr>\n","      <td>2975</td>\n","      <td>0.849700</td>\n","    </tr>\n","    <tr>\n","      <td>2980</td>\n","      <td>0.881600</td>\n","    </tr>\n","    <tr>\n","      <td>2985</td>\n","      <td>0.912000</td>\n","    </tr>\n","    <tr>\n","      <td>2990</td>\n","      <td>0.982400</td>\n","    </tr>\n","    <tr>\n","      <td>2995</td>\n","      <td>0.816500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.942200</td>\n","    </tr>\n","    <tr>\n","      <td>3005</td>\n","      <td>0.953100</td>\n","    </tr>\n","    <tr>\n","      <td>3010</td>\n","      <td>0.879200</td>\n","    </tr>\n","    <tr>\n","      <td>3015</td>\n","      <td>0.930500</td>\n","    </tr>\n","    <tr>\n","      <td>3020</td>\n","      <td>0.957400</td>\n","    </tr>\n","    <tr>\n","      <td>3025</td>\n","      <td>0.973800</td>\n","    </tr>\n","    <tr>\n","      <td>3030</td>\n","      <td>0.950700</td>\n","    </tr>\n","    <tr>\n","      <td>3035</td>\n","      <td>0.886700</td>\n","    </tr>\n","    <tr>\n","      <td>3040</td>\n","      <td>0.873700</td>\n","    </tr>\n","    <tr>\n","      <td>3045</td>\n","      <td>0.856700</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.918400</td>\n","    </tr>\n","    <tr>\n","      <td>3055</td>\n","      <td>0.872900</td>\n","    </tr>\n","    <tr>\n","      <td>3060</td>\n","      <td>0.874500</td>\n","    </tr>\n","    <tr>\n","      <td>3065</td>\n","      <td>0.892500</td>\n","    </tr>\n","    <tr>\n","      <td>3070</td>\n","      <td>0.812900</td>\n","    </tr>\n","    <tr>\n","      <td>3075</td>\n","      <td>1.016000</td>\n","    </tr>\n","    <tr>\n","      <td>3080</td>\n","      <td>0.933600</td>\n","    </tr>\n","    <tr>\n","      <td>3085</td>\n","      <td>0.836600</td>\n","    </tr>\n","    <tr>\n","      <td>3090</td>\n","      <td>1.013700</td>\n","    </tr>\n","    <tr>\n","      <td>3095</td>\n","      <td>0.920700</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.982600</td>\n","    </tr>\n","    <tr>\n","      <td>3105</td>\n","      <td>0.940900</td>\n","    </tr>\n","    <tr>\n","      <td>3110</td>\n","      <td>0.904800</td>\n","    </tr>\n","    <tr>\n","      <td>3115</td>\n","      <td>0.900800</td>\n","    </tr>\n","    <tr>\n","      <td>3120</td>\n","      <td>0.953700</td>\n","    </tr>\n","    <tr>\n","      <td>3125</td>\n","      <td>0.913700</td>\n","    </tr>\n","    <tr>\n","      <td>3130</td>\n","      <td>0.879300</td>\n","    </tr>\n","    <tr>\n","      <td>3135</td>\n","      <td>0.927300</td>\n","    </tr>\n","    <tr>\n","      <td>3140</td>\n","      <td>0.876000</td>\n","    </tr>\n","    <tr>\n","      <td>3145</td>\n","      <td>0.846300</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.864300</td>\n","    </tr>\n","    <tr>\n","      <td>3155</td>\n","      <td>1.007900</td>\n","    </tr>\n","    <tr>\n","      <td>3160</td>\n","      <td>0.996200</td>\n","    </tr>\n","    <tr>\n","      <td>3165</td>\n","      <td>0.918200</td>\n","    </tr>\n","    <tr>\n","      <td>3170</td>\n","      <td>0.887300</td>\n","    </tr>\n","    <tr>\n","      <td>3175</td>\n","      <td>0.886600</td>\n","    </tr>\n","    <tr>\n","      <td>3180</td>\n","      <td>0.873500</td>\n","    </tr>\n","    <tr>\n","      <td>3185</td>\n","      <td>0.815000</td>\n","    </tr>\n","    <tr>\n","      <td>3190</td>\n","      <td>0.948900</td>\n","    </tr>\n","    <tr>\n","      <td>3195</td>\n","      <td>0.932600</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.963800</td>\n","    </tr>\n","    <tr>\n","      <td>3205</td>\n","      <td>0.777500</td>\n","    </tr>\n","    <tr>\n","      <td>3210</td>\n","      <td>0.888000</td>\n","    </tr>\n","    <tr>\n","      <td>3215</td>\n","      <td>0.889200</td>\n","    </tr>\n","    <tr>\n","      <td>3220</td>\n","      <td>0.806700</td>\n","    </tr>\n","    <tr>\n","      <td>3225</td>\n","      <td>0.961500</td>\n","    </tr>\n","    <tr>\n","      <td>3230</td>\n","      <td>0.935700</td>\n","    </tr>\n","    <tr>\n","      <td>3235</td>\n","      <td>0.835700</td>\n","    </tr>\n","    <tr>\n","      <td>3240</td>\n","      <td>0.981900</td>\n","    </tr>\n","    <tr>\n","      <td>3245</td>\n","      <td>0.875600</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.945700</td>\n","    </tr>\n","    <tr>\n","      <td>3255</td>\n","      <td>0.865300</td>\n","    </tr>\n","    <tr>\n","      <td>3260</td>\n","      <td>0.905300</td>\n","    </tr>\n","    <tr>\n","      <td>3265</td>\n","      <td>0.918100</td>\n","    </tr>\n","    <tr>\n","      <td>3270</td>\n","      <td>0.958600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='281' max='281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [281/281 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Multimodal eval results: {'eval_loss': 1.164597988128662, 'eval_runtime': 6.3049, 'eval_samples_per_second': 177.956, 'eval_steps_per_second': 44.568, 'epoch': 10.0}\n","Saved GPT-2 core, tokenizer, and multimodal wrapper to: /content/drive/MyDrive/processed data/data/data/full_multimodal_decoder\n"]}]},{"cell_type":"code","source":["# ==== Multimodal eval: perplexity + summary ====\n","import pandas as pd\n","\n","if \"eval_loss\" in mm_eval_results:\n","    mm_val_ppl = math.exp(mm_eval_results[\"eval_loss\"])\n","    print(\"Multimodal validation perplexity:\", mm_val_ppl)\n","else:\n","    mm_val_ppl = None\n","    print(\"No eval_loss found for multimodal model.\")\n","\n","mm_summary = {\n","    \"model\": [\"ViT + ClinicalBERT → GPT-2 (conditioned)\"],\n","    \"eval_loss\": [mm_eval_results.get(\"eval_loss\", None)],\n","    \"val_perplexity\": [mm_val_ppl],\n","}\n","mm_summary_df = pd.DataFrame(mm_summary)\n","display(mm_summary_df)\n"],"metadata":{"id":"orkbolPjwAlF","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1764727479598,"user_tz":300,"elapsed":72,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"0f2e455c-db84-4ae6-f4e9-330d6f510b86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Multimodal validation perplexity: 3.204634323170742\n"]},{"output_type":"display_data","data":{"text/plain":["                                      model  eval_loss  val_perplexity\n","0  ViT + ClinicalBERT → GPT-2 (conditioned)   1.164598        3.204634"],"text/html":["\n","  <div id=\"df-4694c998-65f5-4ea3-a753-89dc968d1f49\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>eval_loss</th>\n","      <th>val_perplexity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ViT + ClinicalBERT → GPT-2 (conditioned)</td>\n","      <td>1.164598</td>\n","      <td>3.204634</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4694c998-65f5-4ea3-a753-89dc968d1f49')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4694c998-65f5-4ea3-a753-89dc968d1f49 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4694c998-65f5-4ea3-a753-89dc968d1f49');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_3c94270f-4389-4bf0-88c6-4fb08ae42980\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mm_summary_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3c94270f-4389-4bf0-88c6-4fb08ae42980 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('mm_summary_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"mm_summary_df","summary":"{\n  \"name\": \"mm_summary_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ViT + ClinicalBERT \\u2192 GPT-2 (conditioned)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.164597988128662,\n        \"max\": 1.164597988128662,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.164597988128662\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.204634323170742,\n        \"max\": 3.204634323170742,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.204634323170742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["# ==== Optional: Conditioned generation for sanity check ====\n","def generate_conditioned(idx=0, max_new_tokens=80):\n","    mm_model.eval()\n","    with torch.no_grad():\n","        s = mm_val_ds.samples[idx]\n","\n","        img_emb = s[\"image_emb\"]\n","        txt_emb = s[\"text_emb\"]\n","        img_pooled = img_emb.mean(dim=0)\n","        cond_vec = torch.cat([img_pooled, txt_emb], dim=-1).unsqueeze(0).to(device)\n","\n","        generated_ids = tokenizer(\n","            tokenizer.bos_token,\n","            return_tensors=\"pt\"\n","        )[\"input_ids\"].to(device)\n","\n","        for _ in range(max_new_tokens):\n","            token_emb = mm_model.gpt2.transformer.wte(generated_ids)\n","            cond_emb = mm_model.cond_proj(cond_vec).unsqueeze(1)\n","            inputs_embeds = torch.cat([cond_emb, token_emb], dim=1)\n","\n","            attn_mask = torch.ones(\n","                inputs_embeds.size()[:2],\n","                dtype=torch.long,\n","                device=device,\n","            )\n","\n","            outputs = mm_model.gpt2(\n","                inputs_embeds=inputs_embeds,\n","                attention_mask=attn_mask,\n","            )\n","            next_token_logits = outputs.logits[:, -1, :]\n","            next_id = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n","            generated_ids = torch.cat([generated_ids, next_id], dim=1)\n","\n","            if tokenizer.eos_token_id is not None and next_id.item() == tokenizer.eos_token_id:\n","                break\n","\n","        gen_text = tokenizer.decode(generated_ids[0], skip_special_tokens=False)\n","\n","        print(\"=== CONDITIONED GENERATION (val sample idx =\", idx, \") ===\\n\")\n","        print(gen_text)\n","        print(\"\\n---------------- Ground truth (for reference) ----------------\")\n","        print(\"\\n[Impression]\\n\", s[\"impression\"])\n","        print(\"\\n[Full report snippet]\\n\", s[\"full_report\"][:400], \"...\")\n","\n","generate_conditioned(idx=0, max_new_tokens=80)\n"],"metadata":{"id":"cbllM3g3wCFS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764727480603,"user_tz":300,"elapsed":1004,"user":{"displayName":"Nikhil Roy","userId":"13045380208647931674"}},"outputId":"fe71d2f8-3243-40eb-b9d0-a16be66cfb8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== CONDITIONED GENERATION (val sample idx = 0 ) ===\n","\n","<BOS> Indication: -year-old female with chest pain. Comparison: None. Findings: The cardiomediastinal silhouette is within normal limits for appearance. No focal areas of pulmonary consolidation. No pleural effusion. No pneumothorax. Minimal degenerative changes of the thoracic spine. Impression: 1. No acute intrathoracic abnormality. 2\n","\n","---------------- Ground truth (for reference) ----------------\n","\n","[Impression]\n"," 1. Bullous emphysema and interstitial fibrosis. 2. Probably scarring in the left apex, although difficult to exclude a cavitary lesion. 3. Opacities in the bilateral upper lobes could represent scarring, however the absence of comparison exam, recommend short interval followup radiograph or CT thorax to document resolution.\n","\n","[Full report snippet]\n"," Indication: -year-old with . Comparison: None available Findings: There are diffuse bilateral interstitial and alveolar opacities consistent with chronic obstructive lung disease and bullous emphysema. There are irregular opacities in the left lung apex, that could represent a cavitary lesion in the left lung apex.There are streaky opacities in the right upper lobe, scarring. The cardiomediastinal ...\n"]}]}]}