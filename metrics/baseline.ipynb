{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b64105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76afacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cac652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- COLUMN NAMES IN YOUR FILE ---\n",
      "['uid', 'filename', 'projection', 'findings_final', 'impression_final', 'full_report', 'findings_len', 'impression_len', 'full_report_len', 'MeSH', 'Problems', 'split']\n",
      "---------------------------------\n",
      "Look for the one that contains the text report.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Use the path we confirmed works\n",
    "BASE_PATH = r\"C:\\Users\\rthakre\\reports-20251124T181120Z-1-001\\reports\"\n",
    "TRAIN_FILE = os.path.join(BASE_PATH, \"train_reports.csv\")\n",
    "\n",
    "# Read just the first few lines\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "\n",
    "print(\"--- COLUMN NAMES IN YOUR FILE ---\")\n",
    "print(df.columns.tolist())\n",
    "print(\"---------------------------------\")\n",
    "print(\"Look for the one that contains the text report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a344185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Analyzing Training Data...\n",
      "   Most frequent report appears 265 times (5.07% of dataset).\n",
      "   Text: 'normal...'\n",
      "\n",
      "2. Evaluating on Test Data...\n",
      "   Comparing 1121 predictions...\n",
      "\n",
      "========================================\n",
      "üèÜ FINAL BASELINE SCORES (Frequency Model)\n",
      "========================================\n",
      "BLEU-1:  0.0473\n",
      "BLEU-4:  0.0084\n",
      "ROUGE-L: 0.1020\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Cell: Task 1 - Frequency Baseline (FIXED NLTK ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# üõ†Ô∏è FIX: DOWNLOAD MISSING NLTK DATA\n",
    "# =============================================================================\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Path to your report folder\n",
    "BASE_PATH = r\"C:\\Users\\rthakre\\reports-20251124T181120Z-1-001\\reports\"\n",
    "\n",
    "TRAIN_FILE = os.path.join(BASE_PATH, \"train_reports.csv\")\n",
    "TEST_FILE  = os.path.join(BASE_PATH, \"test_reports.csv\")\n",
    "\n",
    "# We are using the column you identified\n",
    "TEXT_COLUMN = 'findings_final' \n",
    "\n",
    "# =============================================================================\n",
    "# 2. BASELINE LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_find_mode(train_path):\n",
    "    print(f\"\\n1. Analyzing Training Data...\")\n",
    "    if not os.path.exists(train_path):\n",
    "        print(f\"‚ùå ERROR: File not found at {train_path}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(train_path)\n",
    "    \n",
    "    # Handle missing text\n",
    "    df[TEXT_COLUMN] = df[TEXT_COLUMN].fillna(\"\")\n",
    "    \n",
    "    # Find the most common report text\n",
    "    all_reports = df[TEXT_COLUMN].str.strip().tolist()\n",
    "    counts = Counter(all_reports)\n",
    "    most_common_text, frequency = counts.most_common(1)[0]\n",
    "    \n",
    "    percentage = (frequency / len(df)) * 100\n",
    "    \n",
    "    print(f\"   Most frequent report appears {frequency} times ({percentage:.2f}% of dataset).\")\n",
    "    print(f\"   Text: '{most_common_text[:100]}...'\") \n",
    "    \n",
    "    return most_common_text\n",
    "\n",
    "def evaluate_baseline(test_path, baseline_prediction):\n",
    "    print(f\"\\n2. Evaluating on Test Data...\")\n",
    "    if not os.path.exists(test_path):\n",
    "        print(f\"‚ùå ERROR: File not found at {test_path}\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.read_csv(test_path)\n",
    "    df[TEXT_COLUMN] = df[TEXT_COLUMN].fillna(\"\")\n",
    "    \n",
    "    ground_truth = df[TEXT_COLUMN].str.strip().tolist()\n",
    "    \n",
    "    # The \"Model\" predicts the exact same text for every image\n",
    "    predictions = [baseline_prediction] * len(ground_truth)\n",
    "    \n",
    "    print(f\"   Comparing {len(ground_truth)} predictions...\")\n",
    "    \n",
    "    # Metrics\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    smooth = SmoothingFunction().method1\n",
    "    \n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_scores = []\n",
    "    \n",
    "    for ref, hyp in zip(ground_truth, predictions):\n",
    "        # Tokenize using the now-downloaded punkt_tab\n",
    "        ref_tokens = nltk.word_tokenize(ref.lower())\n",
    "        hyp_tokens = nltk.word_tokenize(hyp.lower())\n",
    "        \n",
    "        # BLEU-1\n",
    "        bleu1_scores.append(sentence_bleu([ref_tokens], hyp_tokens, weights=(1, 0, 0, 0), smoothing_function=smooth))\n",
    "        \n",
    "        # BLEU-4\n",
    "        bleu4_scores.append(sentence_bleu([ref_tokens], hyp_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth))\n",
    "        \n",
    "        # ROUGE-L\n",
    "        r_score = scorer.score(ref, hyp)\n",
    "        rouge_scores.append(r_score['rougeL'].fmeasure)\n",
    "        \n",
    "    return np.mean(bleu1_scores), np.mean(bleu4_scores), np.mean(rouge_scores)\n",
    "\n",
    "# Run the main logic\n",
    "if os.path.exists(TRAIN_FILE) and os.path.exists(TEST_FILE):\n",
    "    # 1. Train (Find the most common sentence)\n",
    "    baseline_text = load_and_find_mode(TRAIN_FILE)\n",
    "    \n",
    "    if baseline_text:\n",
    "        # 2. Test (Score that sentence against the test set)\n",
    "        b1, b4, rouge = evaluate_baseline(TEST_FILE, baseline_text)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\" FINAL BASELINE SCORES (Frequency Model)\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"BLEU-1:  {b1:.4f}\")\n",
    "        print(f\"BLEU-4:  {b4:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge:.4f}\")\n",
    "        print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a54ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "####part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7311e3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ scikit-learn installed!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])\n",
    "    print(\" scikit-learn installed!\")\n",
    "except:\n",
    "    print(\" Installation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb84981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading CSVs...\n",
      "\n",
      "2. extracting 'pixel features' (No GPU needed)...\n",
      "Processing 5223 images from C:\\Users\\rthakre\\images-20251124T181116Z-1-001\\images\\train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5223/5223 [00:15<00:00, 340.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1121 images from C:\\Users\\rthakre\\images-20251124T181116Z-1-001\\images\\test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1121/1121 [00:04<00:00, 263.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Finding closest matches among 5223 training images...\n",
      "Calculating scores...\n",
      "\n",
      "========================================\n",
      "üèÜ FINAL KNN BASELINE SCORES\n",
      "========================================\n",
      "BLEU-1:  0.2618\n",
      "BLEU-4:  0.0636\n",
      "ROUGE-L: 0.2107\n",
      "========================================\n",
      "This is the score to beat. If the complex model is lower than this,\n",
      "it means the AI isn't even looking at the image correctly.\n"
     ]
    }
   ],
   "source": [
    "# Cell: Task 2 - KNN Baseline (Pixel-Match Version)\n",
    "# This version DOES NOT require PyTorch, avoiding the DLL error.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Using the paths you confirmed earlier\n",
    "REPORT_PATH = r\"C:\\Users\\rthakre\\reports-20251124T181120Z-1-001\\reports\"\n",
    "TRAIN_CSV = os.path.join(REPORT_PATH, \"train_reports.csv\")\n",
    "TEST_CSV  = os.path.join(REPORT_PATH, \"test_reports.csv\")\n",
    "\n",
    "IMAGE_ROOT = r\"C:\\Users\\rthakre\\images-20251124T181116Z-1-001\\images\"\n",
    "TRAIN_IMG_DIR = os.path.join(IMAGE_ROOT, \"train\")\n",
    "TEST_IMG_DIR = os.path.join(IMAGE_ROOT, \"test\")\n",
    "\n",
    "# Column names based on your file\n",
    "TEXT_COL = 'findings_final'\n",
    "FILENAME_COL = 'filename'\n",
    "\n",
    "# =============================================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_flatten_images(image_dir, filenames):\n",
    "    \"\"\"\n",
    "    Reads images, resizes them to 64x64, and uses raw pixels as features.\n",
    "    This mimics \"visual similarity\" without needing a heavy Neural Network.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "    valid_indices = [] \n",
    "    \n",
    "    print(f\"Processing {len(filenames)} images from {image_dir}...\")\n",
    "    \n",
    "    # Resize to 64x64 (thumbnails) for speed\n",
    "    TARGET_SIZE = (64, 64)\n",
    "    \n",
    "    for idx, fname in enumerate(tqdm(filenames)):\n",
    "        img_path = os.path.join(image_dir, fname)\n",
    "        \n",
    "        # Handle missing extensions if necessary\n",
    "        if not os.path.exists(img_path):\n",
    "            if os.path.exists(img_path + \".png\"):\n",
    "                img_path += \".png\"\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            # Open, convert to Grayscale (L), Resize, Flatten\n",
    "            img = Image.open(img_path).convert(\"L\") \n",
    "            img = img.resize(TARGET_SIZE)\n",
    "            # Flatten to a single vector of numbers\n",
    "            arr = np.array(img).flatten()\n",
    "            matrix.append(arr)\n",
    "            valid_indices.append(idx)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return np.array(matrix), valid_indices\n",
    "\n",
    "def calculate_metrics(references, hypotheses):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    smooth = SmoothingFunction().method1\n",
    "    \n",
    "    b1_scores, b4_scores, rouge_scores = [], [], []\n",
    "    \n",
    "    print(\"Calculating scores...\")\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        ref_tok = nltk.word_tokenize(ref.lower())\n",
    "        hyp_tok = nltk.word_tokenize(hyp.lower())\n",
    "        \n",
    "        b1_scores.append(sentence_bleu([ref_tok], hyp_tok, weights=(1,0,0,0), smoothing_function=smooth))\n",
    "        b4_scores.append(sentence_bleu([ref_tok], hyp_tok, weights=(0.25,0.25,0.25,0.25), smoothing_function=smooth))\n",
    "        rouge_scores.append(scorer.score(ref, hyp)['rougeL'].fmeasure)\n",
    "        \n",
    "    return np.mean(b1_scores), np.mean(b4_scores), np.mean(rouge_scores)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "# A. Load Data\n",
    "print(\"\\n1. Loading CSVs...\")\n",
    "if os.path.exists(TRAIN_CSV) and os.path.exists(TEST_CSV):\n",
    "    train_df = pd.read_csv(TRAIN_CSV).dropna(subset=[TEXT_COL, FILENAME_COL])\n",
    "    test_df = pd.read_csv(TEST_CSV).dropna(subset=[TEXT_COL, FILENAME_COL])\n",
    "    \n",
    "    # B. Process Images (Flatten Pixels)\n",
    "    print(\"\\n2. extracting 'pixel features' (No GPU needed)...\")\n",
    "    train_feats, train_indices = load_and_flatten_images(TRAIN_IMG_DIR, train_df[FILENAME_COL].tolist())\n",
    "    train_df_clean = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "    \n",
    "    test_feats, test_indices = load_and_flatten_images(TEST_IMG_DIR, test_df[FILENAME_COL].tolist())\n",
    "    test_df_clean = test_df.iloc[test_indices].reset_index(drop=True)\n",
    "    \n",
    "    if len(train_feats) > 0 and len(test_feats) > 0:\n",
    "        # C. Find Nearest Neighbors based on Pixels\n",
    "        print(f\"\\n3. Finding closest matches among {len(train_feats)} training images...\")\n",
    "        # 'cityblock' (Manhattan distance) works well for comparing pixel brightness\n",
    "        knn = NearestNeighbors(n_neighbors=1, metric='cityblock') \n",
    "        knn.fit(train_feats)\n",
    "        \n",
    "        distances, indices = knn.kneighbors(test_feats)\n",
    "        \n",
    "        # D. Generate Report Predictions\n",
    "        predictions = []\n",
    "        for i in range(len(indices)):\n",
    "            neighbor_idx = indices[i][0]\n",
    "            # We steal the report from the most similar looking training image\n",
    "            predictions.append(train_df_clean.iloc[neighbor_idx][TEXT_COL])\n",
    "            \n",
    "        # E. Score\n",
    "        ground_truth = test_df_clean[TEXT_COL].tolist()\n",
    "        b1, b4, rouge = calculate_metrics(ground_truth, predictions)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\" FINAL KNN BASELINE SCORES\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"BLEU-1:  {b1:.4f}\")\n",
    "        print(f\"BLEU-4:  {b4:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge:.4f}\")\n",
    "        print(\"=\"*40)\n",
    "        print(\"This is the score to beat. If the complex model is lower than this,\")\n",
    "        print(\"it means the AI isn't even looking at the image correctly.\")\n",
    "    else:\n",
    "        print(\"Error: No images were successfully loaded. Check paths.\")\n",
    "else:\n",
    "    print(\"Error: CSV files not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d86e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906f5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rthakre\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fc92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
